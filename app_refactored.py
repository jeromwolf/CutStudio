"""
CutStudio - ë¦¬íŒ©í† ë§ëœ ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜
"""
import streamlit as st
import os
from pathlib import Path
from typing import Optional
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# í”„ë¡ì‹œ ê´€ë ¨ í™˜ê²½ ë³€ìˆ˜ ì •ë¦¬ (Claude ì´ˆê¸°í™” ë¬¸ì œ ë°©ì§€)
proxy_vars = [
    'HTTP_PROXY', 'HTTPS_PROXY', 'http_proxy', 'https_proxy',
    'FTP_PROXY', 'ftp_proxy', 'NO_PROXY', 'no_proxy',
    'ALL_PROXY', 'all_proxy'
]
for var in proxy_vars:
    os.environ.pop(var, None)

# Core ëª¨ë“ˆ
from core.state_manager import AppState
from core.config import AppConfig

# Services ëª¨ë“ˆ
from services.speaker_detection import UnifiedSpeakerDetector
from services.speech_processing import SpeechProcessor
from services.summarization import SummarizationService

# UI ëª¨ë“ˆ
from ui.components import display_speaker_profile, display_timeline, display_statistics

# ê¸°ì¡´ ëª¨ë“ˆ
from video_editor import VideoEditor
from youtube_downloader import YouTubeDownloader
from utils import format_time


# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ğŸ¬ CutStudio - ìŠ¤ë§ˆíŠ¸ ë™ì˜ìƒ í¸ì§‘ê¸°",
    page_icon="ğŸ¬",
    layout="wide"
)


class CutStudioApp:
    """CutStudio ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.state = AppState()
        self.config = AppConfig()
        self.speaker_detector = UnifiedSpeakerDetector()
        self.speech_processor = None
        self.summarizer = SummarizationService()
        self.youtube_downloader = YouTubeDownloader()
        
        # ìš”ì•½ê¸° ì´ˆê¸°í™”
        self.summarizer.initialize_summarizers()
    
    def run(self):
        """ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰"""
        self._display_header()
        self._display_sidebar()
        
        # ë©”ì¸ íƒ­
        tabs = st.tabs([
            "ğŸ“¤ íŒŒì¼ ì—…ë¡œë“œ",
            "ğŸ“º YouTube ë‹¤ìš´ë¡œë“œ",
            "âœ‚ï¸ í¸ì§‘ ë„êµ¬"
        ])
        
        with tabs[0]:
            self._handle_file_upload()
        
        with tabs[1]:
            self._handle_youtube_download()
        
        with tabs[2]:
            self._display_editing_tools()
    
    def _display_header(self):
        """í—¤ë” í‘œì‹œ"""
        st.title("ğŸ¬ CutStudio v3.1")
        st.markdown("AI ê¸°ë°˜ ìŠ¤ë§ˆíŠ¸ ë™ì˜ìƒ í¸ì§‘ê¸°")
    
    def _display_sidebar(self):
        """ì‚¬ì´ë“œë°” í‘œì‹œ"""
        with st.sidebar:
            st.header("âš™ï¸ ì„¤ì •")
            
            # ìš”ì•½ê¸° ìƒíƒœ ë° ì„ íƒ
            st.subheader("AI ìš”ì•½ ì„¤ì •")
            
            # ìš”ì•½ê¸° ìƒíƒœ í‘œì‹œ
            col1, col2 = st.columns(2)
            with col1:
                if self.summarizer.gemini_summarizer:
                    st.success("âœ… Gemini")
                else:
                    st.error("âŒ Gemini")
            
            with col2:
                if self.summarizer.claude_summarizer:
                    st.success("âœ… Claude")
                else:
                    st.info("â¸ï¸ Claude (ë¹„í™œì„±í™”)")
            
            # ì‚¬ìš© ê°€ëŠ¥í•œ ìš”ì•½ê¸° ì„ íƒ
            available_summarizers = []
            if self.summarizer.gemini_summarizer:
                available_summarizers.append("Gemini")
            if self.summarizer.claude_summarizer:
                available_summarizers.append("Claude")
            
            if available_summarizers:
                selected = st.selectbox(
                    "ìš”ì•½ AI ì„ íƒ",
                    available_summarizers
                )
                self.summarizer.active_summarizer = selected.lower()
                st.info(f"í˜„ì¬ ì‚¬ìš© ì¤‘: {selected}")
            else:
                st.warning("âš ï¸ AI ìš”ì•½ê¸°ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                st.info("API í‚¤ë¥¼ í™•ì¸í•˜ê³  ì•±ì„ ì¬ì‹œì‘í•´ì£¼ì„¸ìš”.")
            
            # íŒŒì¼ ê´€ë¦¬
            st.markdown("---")
            st.subheader("ğŸ—‘ï¸ íŒŒì¼ ê´€ë¦¬")
            if st.button("ì„ì‹œ íŒŒì¼ ì •ë¦¬"):
                self._cleanup_temp_files()
    
    def _handle_file_upload(self):
        """íŒŒì¼ ì—…ë¡œë“œ ì²˜ë¦¬"""
        st.header("ğŸ“¤ ë¹„ë””ì˜¤ íŒŒì¼ ì—…ë¡œë“œ")
        
        uploaded_file = st.file_uploader(
            "ë¹„ë””ì˜¤ íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”",
            type=self.config.SUPPORTED_VIDEO_FORMATS
        )
        
        if uploaded_file is not None:
            # íŒŒì¼ ì €ì¥
            temp_path = Path(self.config.TEMP_DIR)
            temp_path.mkdir(exist_ok=True)
            
            video_path = temp_path / uploaded_file.name
            with open(video_path, "wb") as f:
                f.write(uploaded_file.getbuffer())
            
            st.success(f"âœ… íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ: {uploaded_file.name}")
            
            # ë¹„ë””ì˜¤ ì—ë””í„° ì´ˆê¸°í™”
            self.state.video_editor = VideoEditor()
            self.state.video_editor.load_video(str(video_path))
            self.state.video_path = str(video_path)
            
            # ë¹„ë””ì˜¤ ì •ë³´ í‘œì‹œ
            self._display_video_info()
    
    def _handle_youtube_download(self):
        """YouTube ë‹¤ìš´ë¡œë“œ ì²˜ë¦¬"""
        st.header("ğŸ“º YouTube ë™ì˜ìƒ ë‹¤ìš´ë¡œë“œ")
        
        youtube_url = st.text_input(
            "YouTube URLì„ ì…ë ¥í•˜ì„¸ìš”",
            value=st.session_state.get('youtube_url', '')
        )
        
        if st.button("ë‹¤ìš´ë¡œë“œ", type="primary"):
            if youtube_url:
                with st.spinner("ë‹¤ìš´ë¡œë“œ ì¤‘..."):
                    try:
                        # ë¹„ë””ì˜¤ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                        info = self.youtube_downloader.get_video_info(youtube_url)
                        
                        if info:
                            # ë‹¤ìš´ë¡œë“œ ì‹¤í–‰
                            video_path = self.youtube_downloader.download_video(youtube_url)
                            
                            if video_path:
                                st.success("âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
                                
                                # ë¹„ë””ì˜¤ ì—ë””í„° ì´ˆê¸°í™”
                                self.state.video_editor = VideoEditor()
                                self.state.video_editor.load_video(video_path)
                                self.state.video_path = video_path
                                
                                # ë¹„ë””ì˜¤ ì •ë³´ í‘œì‹œ
                                self._display_video_info()
                        else:
                            st.error("ë¹„ë””ì˜¤ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    
                    except Exception as e:
                        st.error(f"ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
    
    def _display_video_info(self):
        """ë¹„ë””ì˜¤ ì •ë³´ í‘œì‹œ"""
        if self.state.video_editor and self.state.video_editor.video_clip:
            video_clip = self.state.video_editor.video_clip
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("ğŸ“ ê¸¸ì´", format_time(video_clip.duration))
            with col2:
                st.metric("ğŸ“ í•´ìƒë„", f"{video_clip.w}x{video_clip.h}")
            with col3:
                st.metric("ğŸï¸ FPS", f"{video_clip.fps:.1f}")
            
            # ë¯¸ë¦¬ë³´ê¸°
            st.video(self.state.video_path)
    
    def _display_editing_tools(self):
        """í¸ì§‘ ë„êµ¬ í‘œì‹œ"""
        if not self.state.video_editor:
            st.info("ë¨¼ì € ë¹„ë””ì˜¤ë¥¼ ì—…ë¡œë“œí•˜ê±°ë‚˜ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”.")
            return
        
        # í¸ì§‘ ë„êµ¬ íƒ­
        edit_tabs = st.tabs([
            "âœ‚ï¸ ìë¥´ê¸°",
            "ğŸ¨ íš¨ê³¼",
            "ğŸ”Š ì˜¤ë””ì˜¤",
            "ğŸ‘¥ í™”ì ë¶„ì„"
        ])
        
        with edit_tabs[0]:
            self._display_cut_tools()
        
        with edit_tabs[1]:
            self._display_effects_tools()
        
        with edit_tabs[2]:
            self._display_audio_tools()
        
        with edit_tabs[3]:
            self._display_speaker_analysis()
    
    def _display_cut_tools(self):
        """ìë¥´ê¸° ë„êµ¬ í‘œì‹œ"""
        st.header("âœ‚ï¸ ë¹„ë””ì˜¤ ìë¥´ê¸°")
        
        video_duration = self.state.video_editor.video_clip.duration
        
        col1, col2 = st.columns(2)
        
        with col1:
            start_time = st.slider(
                "ì‹œì‘ ì‹œê°„",
                0.0,
                video_duration,
                0.0,
                format="%.1f"
            )
        
        with col2:
            end_time = st.slider(
                "ì¢…ë£Œ ì‹œê°„",
                0.0,
                video_duration,
                video_duration,
                format="%.1f"
            )
        
        if st.button("ìë¥´ê¸°", type="primary"):
            if start_time < end_time:
                with st.spinner("ì²˜ë¦¬ ì¤‘..."):
                    # ì„ì‹œ íŒŒì¼ëª… ìƒì„±
                    output_path = Path(self.config.PROCESSED_DIR) / "trimmed_video.mp4"
                    output_path.parent.mkdir(exist_ok=True)
                    
                    # ìë¥´ê¸° ì‹¤í–‰
                    self.state.video_editor.trim_video(
                        start_time,
                        end_time,
                        str(output_path)
                    )
                    
                    st.success("âœ… ìë¥´ê¸° ì™„ë£Œ!")
                    st.video(str(output_path))
                    
                    # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                    with open(output_path, "rb") as f:
                        st.download_button(
                            label="ğŸ“¥ ë‹¤ìš´ë¡œë“œ",
                            data=f,
                            file_name="trimmed_video.mp4",
                            mime="video/mp4"
                        )
            else:
                st.error("ì‹œì‘ ì‹œê°„ì´ ì¢…ë£Œ ì‹œê°„ë³´ë‹¤ ì•ì„œì•¼ í•©ë‹ˆë‹¤.")
    
    def _display_effects_tools(self):
        """íš¨ê³¼ ë„êµ¬ í‘œì‹œ"""
        st.header("ğŸ¨ ë¹„ë””ì˜¤ íš¨ê³¼")
        
        effect_type = st.selectbox(
            "íš¨ê³¼ ì„ íƒ",
            ["í‘ë°±", "í˜ì´ë“œ ì¸/ì•„ì›ƒ", "ì†ë„ ì¡°ì ˆ", "í¬ë¡­"]
        )
        
        if effect_type == "í‘ë°±":
            if st.button("í‘ë°± íš¨ê³¼ ì ìš©"):
                with st.spinner("ì²˜ë¦¬ ì¤‘..."):
                    output_path = Path(self.config.PROCESSED_DIR) / "grayscale_video.mp4"
                    self.state.video_editor.apply_grayscale(str(output_path))
                    st.success("âœ… í‘ë°± íš¨ê³¼ ì ìš© ì™„ë£Œ!")
                    st.video(str(output_path))
        
        elif effect_type == "í˜ì´ë“œ ì¸/ì•„ì›ƒ":
            fade_duration = st.slider("í˜ì´ë“œ ì‹œê°„ (ì´ˆ)", 0.5, 5.0, 1.0)
            if st.button("í˜ì´ë“œ íš¨ê³¼ ì ìš©"):
                with st.spinner("ì²˜ë¦¬ ì¤‘..."):
                    output_path = Path(self.config.PROCESSED_DIR) / "fade_video.mp4"
                    self.state.video_editor.apply_fade(fade_duration, str(output_path))
                    st.success("âœ… í˜ì´ë“œ íš¨ê³¼ ì ìš© ì™„ë£Œ!")
                    st.video(str(output_path))
        
        elif effect_type == "ì†ë„ ì¡°ì ˆ":
            speed_factor = st.slider("ì†ë„ ë°°ìœ¨", 0.5, 2.0, 1.0)
            if st.button("ì†ë„ ì¡°ì ˆ ì ìš©"):
                with st.spinner("ì²˜ë¦¬ ì¤‘..."):
                    output_path = Path(self.config.PROCESSED_DIR) / "speed_video.mp4"
                    self.state.video_editor.change_speed(speed_factor, str(output_path))
                    st.success("âœ… ì†ë„ ì¡°ì ˆ ì™„ë£Œ!")
                    st.video(str(output_path))
        
        elif effect_type == "í¬ë¡­":
            st.info("í¬ë¡­ ê¸°ëŠ¥ì€ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤.")
    
    def _display_audio_tools(self):
        """ì˜¤ë””ì˜¤ ë„êµ¬ í‘œì‹œ"""
        st.header("ğŸ”Š ì˜¤ë””ì˜¤ í¸ì§‘")
        
        audio_option = st.selectbox(
            "ì˜¤ë””ì˜¤ ì˜µì…˜",
            ["ë³¼ë¥¨ ì¡°ì ˆ", "ìŒì†Œê±°", "ì˜¤ë””ì˜¤ ì¶”ì¶œ"]
        )
        
        if audio_option == "ë³¼ë¥¨ ì¡°ì ˆ":
            volume_factor = st.slider("ë³¼ë¥¨ ë°°ìœ¨", 0.0, 2.0, 1.0)
            if st.button("ë³¼ë¥¨ ì¡°ì ˆ ì ìš©"):
                with st.spinner("ì²˜ë¦¬ ì¤‘..."):
                    output_path = Path(self.config.PROCESSED_DIR) / "volume_adjusted.mp4"
                    self.state.video_editor.adjust_volume(volume_factor, str(output_path))
                    st.success("âœ… ë³¼ë¥¨ ì¡°ì ˆ ì™„ë£Œ!")
                    st.video(str(output_path))
        
        elif audio_option == "ìŒì†Œê±°":
            if st.button("ìŒì†Œê±° ì ìš©"):
                with st.spinner("ì²˜ë¦¬ ì¤‘..."):
                    output_path = Path(self.config.PROCESSED_DIR) / "muted_video.mp4"
                    self.state.video_editor.remove_audio(str(output_path))
                    st.success("âœ… ìŒì†Œê±° ì ìš© ì™„ë£Œ!")
                    st.video(str(output_path))
        
        elif audio_option == "ì˜¤ë””ì˜¤ ì¶”ì¶œ":
            if st.button("ì˜¤ë””ì˜¤ ì¶”ì¶œ"):
                with st.spinner("ì²˜ë¦¬ ì¤‘..."):
                    output_path = Path(self.config.PROCESSED_DIR) / "extracted_audio.mp3"
                    self.state.video_editor.extract_audio(str(output_path))
                    st.success("âœ… ì˜¤ë””ì˜¤ ì¶”ì¶œ ì™„ë£Œ!")
                    st.audio(str(output_path))
    
    def _display_speaker_analysis(self):
        """í™”ì ë¶„ì„ í‘œì‹œ"""
        st.header("ğŸ‘¥ AI í™”ì ë¶„ì„")
        
        # í™”ì ê°ì§€ ì„¤ì •
        st.subheader("ğŸ¯ í™”ì ê°ì§€ ì„¤ì •")
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“œ ê°€ì ¸ì˜¤ê¸°
        available_modes = self.speaker_detector.get_available_modes()
        
        col1, col2 = st.columns(2)
        
        with col1:
            detection_mode = st.selectbox(
                "ê°ì§€ ëª¨ë“œ",
                list(available_modes.keys()),
                format_func=lambda x: available_modes[x]['name']
            )
            
            st.caption(available_modes[detection_mode]['description'])
        
        with col2:
            num_speakers = st.number_input(
                "ì˜ˆìƒ í™”ì ìˆ˜ (0=ìë™)",
                min_value=0,
                max_value=10,
                value=0
            )
        
        # ê³ ê¸‰ ì„¤ì •
        with st.expander("âš™ï¸ ê³ ê¸‰ ì„¤ì •"):
            min_duration = st.slider(
                "ìµœì†Œ ì„¸ê·¸ë¨¼íŠ¸ ê¸¸ì´ (ì´ˆ)",
                0.5,
                5.0,
                2.0
            )
            
            whisper_model = st.selectbox(
                "ìŒì„± ì¸ì‹ ëª¨ë¸",
                self.config.WHISPER_MODELS,
                index=0
            )
        
        # í™”ì ê°ì§€ ì‹¤í–‰
        if st.button("ğŸš€ í™”ì ê°ì§€ ì‹œì‘", type="primary"):
            self._run_speaker_detection(
                detection_mode,
                num_speakers if num_speakers > 0 else None,
                min_duration
            )
        
        # ê²°ê³¼ í‘œì‹œ
        if self.state.speaker_segments:
            st.markdown("---")
            
            # í™”ìë³„ í”„ë¡œí•„
            if self.state.segment_profiles:
                st.subheader("ğŸ‘¥ í™”ìë³„ í”„ë¡œí•„")
                display_speaker_profile(self.state.segment_profiles)
            
            # ìŒì„± ì¸ì‹
            if st.button("ğŸ™ï¸ ìŒì„± ì¸ì‹ ì‹œì‘"):
                self._run_speech_recognition(whisper_model)
            
            # íƒ€ì„ë¼ì¸
            if self.state.recognized_segments:
                st.markdown("---")
                display_timeline(
                    self.state.speaker_segments,
                    self.state.video_editor.video_clip,
                    self.state.recognized_segments,
                    self.summarizer.get_active_summarizer()
                )
            
            # í†µê³„
            st.markdown("---")
            display_statistics(
                self.state.speaker_segments,
                self.state.video_editor.video_clip.duration
            )
    
    def _run_speaker_detection(self, mode: str, num_speakers: Optional[int], min_duration: float):
        """í™”ì ê°ì§€ ì‹¤í–‰"""
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        def progress_callback(current, total, message):
            progress = current / total if total > 0 else 0
            progress_bar.progress(progress)
            status_text.text(message)
        
        try:
            # ì˜ˆìƒ ì‹œê°„ ê³„ì‚°
            video_duration = self.state.video_editor.video_clip.duration
            min_time, max_time = self.speaker_detector.estimate_processing_time(
                video_duration,
                mode
            )
            
            st.info(f"ì˜ˆìƒ ì²˜ë¦¬ ì‹œê°„: {format_time(min_time)} ~ {format_time(max_time)}")
            
            # í™”ì ê°ì§€ ì‹¤í–‰
            segments = self.speaker_detector.detect_speakers(
                self.state.video_path,
                mode=mode,
                num_speakers=num_speakers,
                min_duration=min_duration,
                progress_callback=progress_callback
            )
            
            if segments:
                self.state.speaker_segments = segments
                
                # í”„ë¡œí•„ ìƒì„±
                self.state.segment_profiles = self.state.video_editor.generate_speaker_profile(
                    segments
                )
                
                progress_bar.progress(1.0)
                status_text.text("âœ… í™”ì ê°ì§€ ì™„ë£Œ!")
                st.success(f"ì´ {len(segments)}ê°œì˜ ë°œí™” êµ¬ê°„ì„ ê°ì§€í–ˆìŠµë‹ˆë‹¤.")
                
                # ìë™ìœ¼ë¡œ ìŒì„± ì¸ì‹ ì‹œì‘ ì˜µì…˜
                if st.checkbox("ìŒì„± ì¸ì‹ ìë™ ì‹œì‘", value=True):
                    self._run_speech_recognition("tiny")
            else:
                st.error("í™”ìë¥¼ ê°ì§€í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        
        except Exception as e:
            st.error(f"í™”ì ê°ì§€ ì‹¤íŒ¨: {str(e)}")
        
        finally:
            progress_bar.empty()
            status_text.empty()
    
    def _run_speech_recognition(self, model_size: str):
        """ìŒì„± ì¸ì‹ ì‹¤í–‰"""
        if not self.state.speaker_segments:
            st.error("ë¨¼ì € í™”ì ê°ì§€ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
            return
        
        # SpeechProcessor ì´ˆê¸°í™” (ëª¨ë¸ í¬ê¸°ê°€ ë³€ê²½ë˜ë©´ ìƒˆë¡œ ìƒì„±)
        current_model = getattr(self, '_current_model_size', None)
        if not self.speech_processor or current_model != model_size:
            try:
                from speech_transcriber import SpeechRecognizer
                speech_recognizer = SpeechRecognizer(model_size=model_size)
                self.speech_processor = SpeechProcessor(speech_recognizer)
                self._current_model_size = model_size
                st.info(f"Whisper {model_size} ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
            except Exception as e:
                st.error(f"ìŒì„± ì¸ì‹ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
                return
        
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        def progress_callback(current, total, message):
            progress = current / total if total > 0 else 0
            progress_bar.progress(progress)
            status_text.text(message)
        
        try:
            # ìŒì„± ì¸ì‹ ì‹¤í–‰
            recognized_segments = self.speech_processor.execute_recognition(
                self.state.video_path,
                self.state.speaker_segments,
                model_size=model_size,
                progress_callback=progress_callback
            )
            
            if recognized_segments:
                self.state.recognized_segments = recognized_segments
                
                # ê²°ê³¼ ì²˜ë¦¬
                result = self.speech_processor.process_recognition_results(
                    recognized_segments
                )
                
                progress_bar.progress(1.0)
                status_text.text("âœ… ìŒì„± ì¸ì‹ ì™„ë£Œ!")
                
                st.success(
                    f"ì´ {result['recognized_segments']}ê°œ êµ¬ê°„ì—ì„œ "
                    f"ìŒì„±ì„ ì¸ì‹í–ˆìŠµë‹ˆë‹¤. (ì–¸ì–´: {', '.join(result['languages'])})"
                )
                
                # ëŒ€í™” ìš”ì•½ ìƒì„±
                print("ğŸ”„ ëŒ€í™” ìš”ì•½ ìƒì„± ì‹œì‘...")
                self._generate_conversation_summary()
            else:
                st.warning("ì¸ì‹ëœ ìŒì„±ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        except Exception as e:
            st.error(f"ìŒì„± ì¸ì‹ ì‹¤íŒ¨: {str(e)}")
        
        finally:
            progress_bar.empty()
            status_text.empty()
    
    def _generate_conversation_summary(self):
        """ëŒ€í™” ìš”ì•½ ìƒì„±"""
        print("ğŸ“ _generate_conversation_summary() ì‹œì‘")
        
        if not self.state.recognized_segments:
            print("âŒ recognized_segmentsê°€ ì—†ìŒ")
            st.warning("ìŒì„± ì¸ì‹ ê²°ê³¼ê°€ ì—†ì–´ ìš”ì•½ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print(f"âœ… recognized_segments ê°œìˆ˜: {len(self.state.recognized_segments)}")
        
        # ìš”ì•½ê¸° í™•ì¸
        active_summarizer = self.summarizer.get_active_summarizer()
        print(f"ğŸ“¡ active_summarizer: {active_summarizer}")
        
        if not active_summarizer:
            print("âŒ active_summarizerê°€ None")
            st.error("AI ìš”ì•½ê¸°ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
            return
        
        try:
            with st.spinner("AI ìš”ì•½ ìƒì„± ì¤‘..."):
                summary_result = self.summarizer.generate_conversation_summary(
                    self.state.recognized_segments
                )
                
                st.markdown("---")
                st.subheader("ğŸ“ AI ëŒ€í™” ìš”ì•½")
                
                if summary_result.get('success', False):
                    # ì „ì²´ ìš”ì•½
                    st.markdown("### ì „ì²´ ëŒ€í™” ìš”ì•½")
                    summary_text = summary_result.get('summary', 'ìš”ì•½ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
                    st.info(summary_text)
                    
                    # í™”ìë³„ ìš”ì•½
                    speaker_summaries = summary_result.get('speaker_summaries', {})
                    if speaker_summaries:
                        st.markdown("### í™”ìë³„ ìš”ì•½")
                        for speaker, summary in speaker_summaries.items():
                            st.markdown(f"**{speaker}**: {summary}")
                    
                    # í‚¤ì›Œë“œ
                    keywords = summary_result.get('keywords', [])
                    if keywords:
                        st.markdown("### ì£¼ìš” í‚¤ì›Œë“œ")
                        st.write(", ".join(keywords))
                else:
                    st.error(f"ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {summary_result.get('summary', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
                    
        except Exception as e:
            st.error(f"ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            import traceback
            st.code(traceback.format_exc())
    
    def _cleanup_temp_files(self):
        """ì„ì‹œ íŒŒì¼ ì •ë¦¬"""
        try:
            # temp ë””ë ‰í† ë¦¬ ì •ë¦¬
            temp_path = Path(self.config.TEMP_DIR)
            if temp_path.exists():
                for file in temp_path.glob("*"):
                    file.unlink()
            
            # processed ë””ë ‰í† ë¦¬ ì •ë¦¬
            processed_path = Path(self.config.PROCESSED_DIR)
            if processed_path.exists():
                for file in processed_path.glob("*"):
                    file.unlink()
            
            st.success("âœ… ì„ì‹œ íŒŒì¼ì´ ì •ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            st.error(f"íŒŒì¼ ì •ë¦¬ ì‹¤íŒ¨: {str(e)}")


# ì•± ì‹¤í–‰
if __name__ == "__main__":
    app = CutStudioApp()
    app.run()