import streamlit as st
import tempfile
import os
from pathlib import Path
import shutil
import time
from video_editor import VideoEditor
from utils import get_video_info, format_time
from youtube_downloader import YouTubeDownloader
from speech_transcriber import SpeechRecognizer, AdvancedSpeechAnalyzer
try:
    from gemini_summarizer import GeminiSummarizer
    GEMINI_AVAILABLE = True
except Exception as e:
    print(f"Gemini ì‚¬ìš© ë¶ˆê°€: {e}")
    GEMINI_AVAILABLE = False

try:
    from claude_summarizer import ClaudeSummarizer
    CLAUDE_AVAILABLE = True
except Exception as e:
    print(f"Claude ì‚¬ìš© ë¶ˆê°€: {e}")
    CLAUDE_AVAILABLE = False

# .env íŒŒì¼ ë¡œë“œ
from dotenv import load_dotenv
load_dotenv()

st.set_page_config(
    page_title="CutStudio - ë™ì˜ìƒ í¸ì§‘ê¸°",
    page_icon="ğŸ¬",
    layout="wide"
)

if 'video_editor' not in st.session_state:
    st.session_state.video_editor = VideoEditor()

if 'youtube_downloader' not in st.session_state:
    st.session_state.youtube_downloader = YouTubeDownloader()

if 'speech_recognizer' not in st.session_state:
    st.session_state.speech_recognizer = None

if 'gemini_summarizer' not in st.session_state:
    if GEMINI_AVAILABLE:
        try:
            st.session_state.gemini_summarizer = GeminiSummarizer()
        except Exception as e:
            print(f"Gemini ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            st.session_state.gemini_summarizer = None
    else:
        st.session_state.gemini_summarizer = None

if 'claude_summarizer' not in st.session_state:
    if CLAUDE_AVAILABLE:
        try:
            st.session_state.claude_summarizer = ClaudeSummarizer()
        except Exception as e:
            print(f"Claude ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            st.session_state.claude_summarizer = None
    else:
        st.session_state.claude_summarizer = None

def get_summarizer():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ìš”ì•½ê¸° ë°˜í™˜ (Gemini ìš°ì„ , ì‹¤íŒ¨ ì‹œ Claude)"""
    if st.session_state.gemini_summarizer is not None:
        return st.session_state.gemini_summarizer, "Gemini"
    elif st.session_state.claude_summarizer is not None:
        return st.session_state.claude_summarizer, "Claude"
    else:
        return None, None

def smart_summarize_text(text: str, max_length: int = 150) -> tuple:
    """ìŠ¤ë§ˆíŠ¸ í…ìŠ¤íŠ¸ ìš”ì•½ (Gemini ì‹¤íŒ¨ ì‹œ Claude ìë™ ì „í™˜)"""
    # ë¨¼ì € Gemini ì‹œë„
    if st.session_state.gemini_summarizer is not None:
        try:
            summary = st.session_state.gemini_summarizer.summarize_text(text, max_length)
            # API í• ë‹¹ëŸ‰ ì´ˆê³¼ í‘œì‹œê°€ ìˆìœ¼ë©´ ì‹¤íŒ¨ë¡œ ê°„ì£¼
            if "[API í• ë‹¹ëŸ‰ ì´ˆê³¼]" not in summary:
                return summary, "Gemini"
        except:
            pass
    
    # Gemini ì‹¤íŒ¨ ì‹œ Claude ì‹œë„
    if st.session_state.claude_summarizer is not None:
        try:
            summary = st.session_state.claude_summarizer.summarize_text(text, max_length)
            return summary, "Claude"
        except:
            pass
    
    # ë‘˜ ë‹¤ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ìš”ì•½
    return text[:max_length] + "..." if len(text) > max_length else text, "ê¸°ë³¸"

st.title("ğŸ¬ CutStudio - ë™ì˜ìƒ í¸ì§‘ê¸°")
st.markdown("---")

# íƒ­ ìƒì„±: íŒŒì¼ ì—…ë¡œë“œì™€ YouTube ë‹¤ìš´ë¡œë“œ
upload_tab, youtube_tab = st.tabs(["ğŸ“ íŒŒì¼ ì—…ë¡œë“œ", "ğŸ“º YouTube ë‹¤ìš´ë¡œë“œ"])

with upload_tab:
    uploaded_file = st.file_uploader(
        "ë™ì˜ìƒ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”",
        type=['mp4', 'avi', 'mov', 'mkv'],
        help="ì§€ì› í˜•ì‹: MP4, AVI, MOV, MKV"
    )

with youtube_tab:
    st.write("### YouTube ë™ì˜ìƒ ë‹¤ìš´ë¡œë“œ")
    
    youtube_url = st.text_input(
        "YouTube URLì„ ì…ë ¥í•˜ì„¸ìš”",
        placeholder="https://www.youtube.com/watch?v=..."
    )
    
    if youtube_url:
        if st.button("ë™ì˜ìƒ ì •ë³´ ê°€ì ¸ì˜¤ê¸°", type="primary"):
            with st.spinner("ë™ì˜ìƒ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘..."):
                video_info = st.session_state.youtube_downloader.get_video_info(youtube_url)
                
                if video_info:
                    st.session_state.youtube_info = video_info
                    st.success("ë™ì˜ìƒ ì •ë³´ë¥¼ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤!")
                else:
                    st.error("ë™ì˜ìƒ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. URLì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        
        # ë™ì˜ìƒ ì •ë³´ í‘œì‹œ
        if 'youtube_info' in st.session_state and st.session_state.youtube_info:
            info = st.session_state.youtube_info
            
            col1, col2 = st.columns([1, 2])
            
            with col1:
                if info['thumbnail']:
                    st.image(info['thumbnail'])
            
            with col2:
                st.write(f"**ì œëª©:** {info['title']}")
                st.write(f"**ì—…ë¡œë”:** {info['uploader']}")
                st.write(f"**ê¸¸ì´:** {format_time(info['duration'])}")
                st.write(f"**ì¡°íšŒìˆ˜:** {info['view_count']:,}")
                if info['like_count']:
                    st.write(f"**ì¢‹ì•„ìš”:** {info['like_count']:,}")
            
            st.markdown("---")
            
            # ë‹¤ìš´ë¡œë“œ ì˜µì…˜
            download_type = st.radio(
                "ë‹¤ìš´ë¡œë“œ í˜•ì‹ ì„ íƒ",
                ["ë™ì˜ìƒ (MP4)", "ì˜¤ë””ì˜¤ë§Œ (MP3)"],
                horizontal=True
            )
            
            if download_type == "ë™ì˜ìƒ (MP4)":
                # í•´ìƒë„ ì„ íƒ
                if info['formats']:
                    format_options = [f"{fmt['resolution']} ({fmt['ext']})" for fmt in info['formats']]
                    format_ids = [fmt['format_id'] for fmt in info['formats']]
                    
                    selected_index = st.selectbox(
                        "í•´ìƒë„ ì„ íƒ",
                        range(len(format_options)),
                        format_func=lambda x: format_options[x]
                    )
                    selected_format_id = format_ids[selected_index]
                else:
                    selected_format_id = None
            
            # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
            if st.button("ë‹¤ìš´ë¡œë“œ ì‹œì‘", type="primary", key="download_youtube"):
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                def update_progress(percent, downloaded, total):
                    progress_bar.progress(int(percent))
                    if total > 0:
                        status_text.text(f"ë‹¤ìš´ë¡œë“œ ì¤‘... {percent:.1f}% ({downloaded/1024/1024:.1f}MB / {total/1024/1024:.1f}MB)")
                
                with st.spinner("ë‹¤ìš´ë¡œë“œ ì¤‘..."):
                    if download_type == "ë™ì˜ìƒ (MP4)":
                        file_path = st.session_state.youtube_downloader.download_video(
                            youtube_url, 
                            selected_format_id if 'selected_format_id' in locals() else None,
                            update_progress
                        )
                    else:
                        file_path = st.session_state.youtube_downloader.download_audio_only(
                            youtube_url,
                            update_progress
                        )
                
                if file_path:
                    st.success("ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
                    
                    # ë™ì˜ìƒì¸ ê²½ìš° í¸ì§‘ì„ ìœ„í•´ ë¡œë“œ
                    if download_type == "ë™ì˜ìƒ (MP4)":
                        st.session_state.video_editor.load_video(file_path)
                        st.session_state.youtube_video_path = file_path
                        st.info("ë‹¤ìš´ë¡œë“œëœ ë™ì˜ìƒì´ í¸ì§‘ì„ ìœ„í•´ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤. ì•„ë˜ì—ì„œ í¸ì§‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                    
                    # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                    with open(file_path, "rb") as file:
                        st.download_button(
                            label=f"íŒŒì¼ ë‹¤ìš´ë¡œë“œ ({os.path.basename(file_path)})",
                            data=file,
                            file_name=os.path.basename(file_path),
                            mime="video/mp4" if download_type == "ë™ì˜ìƒ (MP4)" else "audio/mp3"
                        )
                else:
                    st.error("ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

# ë¹„ë””ì˜¤ ì²˜ë¦¬ (ì—…ë¡œë“œ ë˜ëŠ” YouTube ë‹¤ìš´ë¡œë“œ)
video_loaded = False

if uploaded_file is not None:
    temp_dir = Path("temp")
    temp_dir.mkdir(exist_ok=True)
    
    temp_file_path = temp_dir / uploaded_file.name
    with open(temp_file_path, "wb") as f:
        f.write(uploaded_file.getbuffer())
    
    st.session_state.video_editor.load_video(str(temp_file_path))
    video_loaded = True
elif 'youtube_video_path' in st.session_state:
    temp_file_path = st.session_state.youtube_video_path
    video_loaded = True

if video_loaded and temp_file_path:
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("ì›ë³¸ ë™ì˜ìƒ")
        st.video(str(temp_file_path))
    
    with col2:
        st.subheader("ë™ì˜ìƒ ì •ë³´")
        video_info = get_video_info(str(temp_file_path))
        st.write(f"**ì‹œê°„:** {format_time(video_info['duration'])}")
        st.write(f"**í•´ìƒë„:** {video_info['width']}x{video_info['height']}")
        st.write(f"**FPS:** {video_info['fps']:.2f}")
    
    st.markdown("---")
    st.subheader("í¸ì§‘ ë„êµ¬")
    
    tab1, tab2, tab3, tab4 = st.tabs(["âœ‚ï¸ ìë¥´ê¸°", "ğŸï¸ íŠ¸ë¦¼", "ğŸ¨ íš¨ê³¼", "ğŸ‘¥ í™”ì êµ¬ë¶„"])
    
    with tab1:
        st.write("**êµ¬ê°„ ìë¥´ê¸°**")
        col1, col2 = st.columns(2)
        with col1:
            start_time = st.number_input(
                "ì‹œì‘ ì‹œê°„ (ì´ˆ)",
                min_value=0.0,
                max_value=video_info['duration'],
                value=0.0,
                step=0.1
            )
        with col2:
            end_time = st.number_input(
                "ì¢…ë£Œ ì‹œê°„ (ì´ˆ)",
                min_value=0.0,
                max_value=video_info['duration'],
                value=video_info['duration'],
                step=0.1
            )
        
        if st.button("ìë¥´ê¸°", type="primary"):
            with st.spinner("ë™ì˜ìƒì„ ìë¥´ëŠ” ì¤‘..."):
                output_path = st.session_state.video_editor.cut_video(start_time, end_time)
                if output_path:
                    st.success("ë™ì˜ìƒ ìë¥´ê¸° ì™„ë£Œ!")
                    st.video(output_path)
                    
                    with open(output_path, "rb") as file:
                        st.download_button(
                            label="í¸ì§‘ëœ ë™ì˜ìƒ ë‹¤ìš´ë¡œë“œ",
                            data=file,
                            file_name=f"cut_{os.path.basename(temp_file_path)}",
                            mime="video/mp4"
                        )
    
    with tab2:
        st.write("**ë™ì˜ìƒ íŠ¸ë¦¼ (ì•ë’¤ ì œê±°)**")
        col1, col2 = st.columns(2)
        with col1:
            trim_start = st.number_input(
                "ì•ë¶€ë¶„ ì œê±° (ì´ˆ)",
                min_value=0.0,
                max_value=video_info['duration']/2,
                value=0.0,
                step=0.1
            )
        with col2:
            trim_end = st.number_input(
                "ë’·ë¶€ë¶„ ì œê±° (ì´ˆ)",
                min_value=0.0,
                max_value=video_info['duration']/2,
                value=0.0,
                step=0.1
            )
        
        if st.button("íŠ¸ë¦¼í•˜ê¸°", type="primary", key="trim"):
            with st.spinner("ë™ì˜ìƒì„ íŠ¸ë¦¼í•˜ëŠ” ì¤‘..."):
                output_path = st.session_state.video_editor.trim_video(trim_start, trim_end)
                if output_path:
                    st.success("ë™ì˜ìƒ íŠ¸ë¦¼ ì™„ë£Œ!")
                    st.video(output_path)
                    
                    with open(output_path, "rb") as file:
                        st.download_button(
                            label="íŠ¸ë¦¼ëœ ë™ì˜ìƒ ë‹¤ìš´ë¡œë“œ",
                            data=file,
                            file_name=f"trim_{os.path.basename(temp_file_path)}",
                            mime="video/mp4",
                            key="download_trim"
                        )
    
    with tab3:
        st.write("**ë™ì˜ìƒ íš¨ê³¼**")
        
        effect_type = st.selectbox(
            "íš¨ê³¼ ì„ íƒ",
            ["ì—†ìŒ", "í‘ë°±", "í˜ì´ë“œ ì¸", "í˜ì´ë“œ ì•„ì›ƒ", "ì†ë„ ë³€ê²½"]
        )
        
        if effect_type == "ì†ë„ ë³€ê²½":
            speed = st.slider(
                "ì¬ìƒ ì†ë„",
                min_value=0.5,
                max_value=2.0,
                value=1.0,
                step=0.1
            )
        
        if st.button("íš¨ê³¼ ì ìš©", type="primary", key="effect"):
            with st.spinner("íš¨ê³¼ë¥¼ ì ìš©í•˜ëŠ” ì¤‘..."):
                if effect_type == "í‘ë°±":
                    output_path = st.session_state.video_editor.apply_grayscale()
                elif effect_type == "í˜ì´ë“œ ì¸":
                    output_path = st.session_state.video_editor.apply_fade_in()
                elif effect_type == "í˜ì´ë“œ ì•„ì›ƒ":
                    output_path = st.session_state.video_editor.apply_fade_out()
                elif effect_type == "ì†ë„ ë³€ê²½":
                    output_path = st.session_state.video_editor.change_speed(speed)
                else:
                    output_path = None
                
                if output_path:
                    st.success("íš¨ê³¼ ì ìš© ì™„ë£Œ!")
                    st.video(output_path)
                    
                    with open(output_path, "rb") as file:
                        st.download_button(
                            label="íš¨ê³¼ ì ìš©ëœ ë™ì˜ìƒ ë‹¤ìš´ë¡œë“œ",
                            data=file,
                            file_name=f"effect_{os.path.basename(temp_file_path)}",
                            mime="video/mp4",
                            key="download_effect"
                        )
    
    with tab4:
        st.write("**í™”ìë³„ êµ¬ê°„ ê°ì§€ ë° ìë¥´ê¸°**")
        st.info("ë™ì˜ìƒì—ì„œ í™”ìë¥¼ êµ¬ë¶„í•˜ì—¬ ê° í™”ìì˜ ë°œí™” êµ¬ê°„ì„ ìë™ìœ¼ë¡œ ê°ì§€í•©ë‹ˆë‹¤.")
        
        col1, col2, col3 = st.columns([2, 2, 2])
        with col1:
            min_duration = st.slider(
                "ìµœì†Œ ë°œí™” ì‹œê°„ (ì´ˆ)",
                min_value=0.5,
                max_value=5.0,
                value=2.0,
                step=0.5,
                help="ì´ ì‹œê°„ë³´ë‹¤ ì§§ì€ ë°œí™”ëŠ” ë¬´ì‹œë©ë‹ˆë‹¤"
            )
        
        with col2:
            speaker_option = st.selectbox(
                "í™”ì ìˆ˜ ì„¤ì •",
                ["ìë™ ê°ì§€", "2ëª…", "3ëª…", "4ëª…", "5ëª…", "6ëª…"],
                help="ìë™ ê°ì§€ë¥¼ ì„ íƒí•˜ë©´ AIê°€ í™”ì ìˆ˜ë¥¼ ì¶”ì •í•©ë‹ˆë‹¤"
            )
            
            if speaker_option == "ìë™ ê°ì§€":
                num_speakers = None
            else:
                num_speakers = int(speaker_option[0])
        
        with col3:
            detection_method = st.selectbox(
                "ê°ì§€ ë°©ë²•",
                ["í—ˆê¹…í˜ì´ìŠ¤ AI (ìµœì‹ )", "ì‹¤ìš©ì  (ê¶Œì¥)", "ê³ ê¸‰ (í–¥ìƒëœ íŠ¹ì§• + ìŠ¤í™íŠ¸ëŸ´)", "ìë™ (MFCC + í´ëŸ¬ìŠ¤í„°ë§)", "ê°„ë‹¨ (ì—ë„ˆì§€ ê¸°ë°˜)"],
                help="í—ˆê¹…í˜ì´ìŠ¤: ìµœì‹  AI ëª¨ë¸ ì‚¬ìš© (ì •í™•ë„ ìµœê³ ), ì‹¤ìš©ì : ì†ë„ì™€ ì •í™•ë„ì˜ ê· í˜• (1-2ë¶„), ê³ ê¸‰: ë†’ì€ ì •í™•ë„ (5-10ë¶„), ìë™: ê¸°ë³¸ ì„±ëŠ¥, ê°„ë‹¨: ë¹ ë¥´ì§€ë§Œ ëœ ì •í™•í•¨"
            )
        
        if st.button("í™”ì êµ¬ê°„ ê°ì§€", type="primary", key="detect_speakers"):
            if detection_method.startswith("í—ˆê¹…í˜ì´ìŠ¤"):
                st.success("ğŸ¤— í—ˆê¹…í˜ì´ìŠ¤ AI ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤ (pyannote/speaker-diarization-3.1)")
                st.info("""
                ğŸš€ **í—ˆê¹…í˜ì´ìŠ¤ AI ê°ì§€ ì§„í–‰ ë‹¨ê³„:**
                1. ì˜¤ë””ì˜¤ ì¶”ì¶œ
                2. Pyannote 3.1 ëª¨ë¸ë¡œ í™”ì ë¶„ë¦¬
                3. ìë™ í™”ì ìˆ˜ ê°ì§€ ë° ì„¸ê·¸ë¨¼íŠ¸ ì¶”ì¶œ
                4. ë†’ì€ ì •í™•ë„ì˜ í™”ì êµ¬ë¶„
                
                **ì°¸ê³ :** ì²˜ìŒ ì‹¤í–‰ ì‹œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œë¡œ ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                """)
                
                # í—ˆê¹…í˜ì´ìŠ¤ í† í° í™•ì¸
                if not os.getenv("HUGGINGFACE_TOKEN"):
                    st.error("âš ï¸ í—ˆê¹…í˜ì´ìŠ¤ í† í°ì´ í•„ìš”í•©ë‹ˆë‹¤!")
                    st.markdown("""
                    **í† í° ì„¤ì • ë°©ë²•:**
                    1. https://huggingface.co/settings/tokens ì—ì„œ í† í° ìƒì„±
                    2. í™˜ê²½ë³€ìˆ˜ ì„¤ì •: `export HUGGINGFACE_TOKEN=your_token_here`
                    3. ë˜ëŠ” `.env` íŒŒì¼ì— ì¶”ê°€: `HUGGINGFACE_TOKEN=your_token_here`
                    """)
                    st.stop()
                    
            elif detection_method.startswith("ì‹¤ìš©ì "):
                st.success("âœ… ì‹¤ìš©ì  ê°ì§€ëŠ” ì†ë„ì™€ ì •í™•ë„ì˜ ê· í˜•ì„ ì œê³µí•©ë‹ˆë‹¤ (1-2ë¶„)")
                st.info("""
                âš¡ **ì‹¤ìš©ì  ê°ì§€ ì§„í–‰ ë‹¨ê³„:**
                1. ì˜¤ë””ì˜¤ ì¶”ì¶œ
                2. ë¹ ë¥¸ ìŒì„± êµ¬ê°„ ê²€ì¶œ (Silero VAD)
                3. í•µì‹¬ íŠ¹ì§•ë§Œ ì¶”ì¶œ (MFCC 13ê°œ, ê¸°ë³¸ í”¼ì¹˜, ìŠ¤í™íŠ¸ëŸ´)
                4. ì ì‘í˜• K-means í´ëŸ¬ìŠ¤í„°ë§
                5. ë¹ ë¥¸ í›„ì²˜ë¦¬
                """)
            elif detection_method.startswith("ê³ ê¸‰"):
                st.warning("âš ï¸ ê³ ê¸‰ ê°ì§€ëŠ” ì •í™•í•˜ì§€ë§Œ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦½ë‹ˆë‹¤ (1-3ë¶„)")
                st.info("""
                ğŸ” **ì§„í–‰ ë‹¨ê³„:**
                1. ì˜¤ë””ì˜¤ ì¶”ì¶œ
                2. ìŒì„± êµ¬ê°„ ê²€ì¶œ (Silero VAD)
                3. ê° êµ¬ê°„ì—ì„œ íŠ¹ì§• ì¶”ì¶œ (MFCC, í”¼ì¹˜, í¬ë¨¼íŠ¸ ë“±)
                4. í™”ì í´ëŸ¬ìŠ¤í„°ë§
                5. í›„ì²˜ë¦¬ ë° ë³‘í•©
                """)
            
            # ì§„í–‰ ìƒí™© í‘œì‹œë¥¼ ìœ„í•œ ì»¨í…Œì´ë„ˆ
            progress_container = st.empty()
            
            with progress_container.container():
                st.info(f"ğŸ¯ í™”ì êµ¬ê°„ì„ ê°ì§€í•˜ëŠ” ì¤‘... ({detection_method})")
                
                # ë™ì˜ìƒ ê¸¸ì´ í™•ì¸
                video_info = get_video_info(st.session_state.video_editor.video_path)
                if video_info and 'duration' in video_info:
                    duration = video_info['duration']
                    st.write(f"ğŸ“¹ ë™ì˜ìƒ ê¸¸ì´: {format_time(duration)}")
                    
                    if detection_method.startswith("í—ˆê¹…í˜ì´ìŠ¤"):
                        estimated_time = duration * 0.3
                        st.warning(f"â±ï¸ ì˜ˆìƒ ì²˜ë¦¬ ì‹œê°„: {int(estimated_time)}ì´ˆ ~ {int(estimated_time*2)}ì´ˆ")
                        st.info("ğŸ’¡ íŒ: ì²˜ìŒ ì‹¤í–‰ ì‹œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œë¡œ ì¶”ê°€ ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤ (ì•½ 1-2GB)")
                        
                        # ëŒ€ì•ˆ ì œì‹œ
                        with st.expander("ğŸš€ ë” ë¹ ë¥¸ ëŒ€ì•ˆ"):
                            st.write("""
                            **ì‹œê°„ì´ ë„ˆë¬´ ì˜¤ë˜ ê±¸ë¦°ë‹¤ë©´:**
                            1. **"ì‹¤ìš©ì  (ê¶Œì¥)"** ë°©ë²•ì„ ì‚¬ìš©í•´ë³´ì„¸ìš” - 1-2ë¶„ ë‚´ ì²˜ë¦¬
                            2. **"ê°„ë‹¨ (ì—ë„ˆì§€ ê¸°ë°˜)"** ë°©ë²•ì€ ê°€ì¥ ë¹ ë¥´ì§€ë§Œ ì •í™•ë„ê°€ ë‚®ìŠµë‹ˆë‹¤
                            3. ê¸´ ë™ì˜ìƒì€ ë¨¼ì € ì˜ë¼ì„œ ì²˜ë¦¬í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤
                            """)
                
                use_simple = detection_method.startswith("ê°„ë‹¨")
                use_advanced = detection_method.startswith("ê³ ê¸‰")
                use_enhanced = detection_method.startswith("í–¥ìƒëœ")
                use_practical = detection_method.startswith("ì‹¤ìš©ì ")
                use_huggingface = detection_method.startswith("í—ˆê¹…í˜ì´ìŠ¤")
                
                # ì‹œì‘ ì‹œê°„ ê¸°ë¡
                start_time = time.time()
                
                # ì˜ˆìƒ ì‹œê°„ ê³„ì‚°
                estimated_total = 60  # ê¸°ë³¸ê°’
                if detection_method.startswith("í—ˆê¹…í˜ì´ìŠ¤") and duration:
                    estimated_total = max(duration * 0.4, 30)
                elif detection_method.startswith("ì‹¤ìš©ì "):
                    estimated_total = 120
                elif detection_method.startswith("ê³ ê¸‰"):
                    estimated_total = max(duration * 0.8, 180)
                elif detection_method.startswith("ê°„ë‹¨"):
                    estimated_total = 30
                
                # ì‹œì‘ ì‹œê°„ê³¼ ì˜ˆìƒ ì¢…ë£Œ ì‹œê°„ ê³„ì‚°
                start_time_str = time.strftime('%H:%M:%S')
                estimated_end_time = start_time + estimated_total
                estimated_end_str = time.strftime('%H:%M:%S', time.localtime(estimated_end_time))
                
                # Streamlit ë„¤ì´í‹°ë¸Œ ì»´í¬ë„ŒíŠ¸ë¡œ ì‹œì‘ ì •ë³´ í‘œì‹œ
                st.success("ğŸ¯ **í™”ì êµ¬ê°„ ê°ì§€ ì‹œì‘**")
                
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.metric(
                        label="ğŸš€ ì‹œì‘ ì‹œê°„",
                        value=start_time_str
                    )
                
                with col2:
                    st.metric(
                        label="ğŸ ì˜ˆìƒ ì¢…ë£Œ",
                        value=estimated_end_str
                    )
                
                with col3:
                    st.metric(
                        label="â±ï¸ ì˜ˆìƒ ì†Œìš”",
                        value=f"{int(estimated_total//60)}ë¶„ {int(estimated_total%60)}ì´ˆ"
                    )
                
                st.info(f"ğŸ¤– **ì‚¬ìš© ë°©ë²•**: {detection_method}")
                st.info(f"ğŸ“º **ë™ì˜ìƒ ê¸¸ì´**: {format_time(duration) if duration else 'ì•Œ ìˆ˜ ì—†ìŒ'}")
                
                # ë‹¨ê³„ë³„ ì§„í–‰ ìƒí™© í‘œì‹œ
                with st.expander("ğŸ“‹ ì²˜ë¦¬ ë‹¨ê³„", expanded=True):
                    st.write("ğŸ”„ **1ë‹¨ê³„**: ì˜¤ë””ì˜¤ ì¶”ì¶œ ë° ì „ì²˜ë¦¬")
                    st.write("ğŸ”„ **2ë‹¨ê³„**: ìŒì„± íŠ¹ì§• ë¶„ì„") 
                    st.write("ğŸ”„ **3ë‹¨ê³„**: í™”ì í´ëŸ¬ìŠ¤í„°ë§")
                    st.write("ğŸ”„ **4ë‹¨ê³„**: ê²°ê³¼ í›„ì²˜ë¦¬")
                    st.info(f"ğŸ¤– í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ ë°©ë²•: **{detection_method}**")
                
                # í™”ì ê°ì§€ ì‹¤í–‰ (st.spinner ì‚¬ìš©)
                with st.spinner("ğŸ¯ í™”ì êµ¬ê°„ì„ ë¶„ì„í•˜ëŠ” ì¤‘... ì²˜ë¦¬ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤."):
                    segments = st.session_state.video_editor.detect_speakers(
                        min_duration, 
                        num_speakers=num_speakers,
                        use_simple=use_simple,
                        use_advanced=use_advanced,
                        use_enhanced=use_enhanced,
                        use_practical=use_practical,
                        use_huggingface=use_huggingface
                    )
                
                # ìµœì¢… ì™„ë£Œ ì‹œê°„
                elapsed_time = time.time() - start_time
                end_time = time.strftime('%H:%M:%S')
                
                # ì‹¤ì œ ì™„ë£Œ ì‹œê°„ê³¼ ë¹„êµ ë¶„ì„
                actual_end_time = time.time()
                actual_end_str = time.strftime('%H:%M:%S', time.localtime(actual_end_time))
                time_diff = elapsed_time - estimated_total
                estimated_end_str = time.strftime('%H:%M:%S', time.localtime(start_time + estimated_total))
                
                # Streamlit ë„¤ì´í‹°ë¸Œ ì»´í¬ë„ŒíŠ¸ë¡œ ì™„ë£Œ ì •ë³´ í‘œì‹œ
                st.success("ğŸ‰ **ì²˜ë¦¬ ì™„ë£Œ!**")
                
                # ì‹œê°„ ì •ë³´ í‘œì‹œ
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.metric(
                        label="ğŸš€ ì‹œì‘ ì‹œê°„",
                        value=time.strftime('%H:%M:%S', time.localtime(start_time))
                    )
                
                with col2:
                    st.metric(
                        label="ğŸ ì™„ë£Œ ì‹œê°„",
                        value=actual_end_str
                    )
                
                with col3:
                    st.metric(
                        label="â±ï¸ ì´ ì†Œìš”ì‹œê°„",
                        value=f"{int(elapsed_time//60)}ë¶„ {elapsed_time%60:.1f}ì´ˆ"
                    )
                
                # ì˜ˆìƒ vs ì‹¤ì œ ë¹„êµ
                st.info("ğŸ“Š **ì˜ˆìƒ vs ì‹¤ì œ ë¹„êµ**")
                
                col_a, col_b = st.columns(2)
                with col_a:
                    st.write(f"**ì˜ˆìƒ ì¢…ë£Œ**: {estimated_end_str}")
                with col_b:
                    st.write(f"**ì‹¤ì œ ì¢…ë£Œ**: {actual_end_str}")
                
                # ì„±ëŠ¥ ë¶„ì„
                time_diff_msg = ""
                if time_diff < -10:
                    time_diff_msg = f"ğŸš€ **{abs(int(time_diff))}ì´ˆ ë¹¨ëìŠµë‹ˆë‹¤!**"
                    st.success(time_diff_msg)
                elif time_diff > 30:
                    time_diff_msg = f"â° **{int(time_diff)}ì´ˆ ë” ê±¸ë ¸ìŠµë‹ˆë‹¤.**"
                    st.warning(time_diff_msg)
                else:
                    time_diff_msg = "âœ¨ **ì˜ˆìƒ ì‹œê°„ê³¼ ê±°ì˜ ì¼ì¹˜í•©ë‹ˆë‹¤!**"
                    st.info(time_diff_msg)
                
                # ì„±ëŠ¥ í‰ê°€ ë©”ì‹œì§€
                if elapsed_time < estimated_total * 0.7:
                    st.success(f"ğŸš€ ì˜ˆìƒë³´ë‹¤ **{estimated_total - elapsed_time:.1f}ì´ˆ** ë¹ ë¥´ê²Œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
                elif elapsed_time > estimated_total * 1.5:
                    st.warning(f"â° ì˜ˆìƒë³´ë‹¤ **{elapsed_time - estimated_total:.1f}ì´ˆ** ë” ê±¸ë ¸ìŠµë‹ˆë‹¤. ë³µì¡í•œ ì˜¤ë””ì˜¤ì´ê±°ë‚˜ ì‹œìŠ¤í…œ ë¶€í•˜ê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                else:
                    st.info("âœ¨ ì˜ˆìƒ ì‹œê°„ ë²”ìœ„ ë‚´ì— ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
                
                # ê²°ê³¼ ìš”ì•½
                st.success(f"ğŸ‰ ì²˜ë¦¬ ì™„ë£Œ! ì´ ì†Œìš” ì‹œê°„: **{elapsed_time:.1f}ì´ˆ**")
                
                # ì„±ëŠ¥ í‰ê°€
                if elapsed_time < estimated_total * 0.7:
                    st.info("ğŸš€ ì˜ˆìƒë³´ë‹¤ **ë¹ ë¥´ê²Œ** ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
                elif elapsed_time > estimated_total * 1.3:
                    st.warning("â° ì˜ˆìƒë³´ë‹¤ ì‹œê°„ì´ **ì˜¤ë˜** ê±¸ë ¸ìŠµë‹ˆë‹¤. ê¸´ ë™ì˜ìƒì´ê±°ë‚˜ ë³µì¡í•œ ì˜¤ë””ì˜¤ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                else:
                    st.info("âœ¨ ì˜ˆìƒ ì‹œê°„ ë‚´ì— ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
                
                if segments:
                    st.session_state.speaker_segments = segments
                    st.success(f"{len(segments)}ê°œì˜ í™”ì êµ¬ê°„ì„ ê°ì§€í–ˆìŠµë‹ˆë‹¤!")
                    
                    # í™”ìë³„ í†µê³„ í‘œì‹œ
                    speakers = {}
                    for seg in segments:
                        speaker = seg['speaker']
                        if speaker not in speakers:
                            speakers[speaker] = {'count': 0, 'total_duration': 0}
                        speakers[speaker]['count'] += 1
                        speakers[speaker]['total_duration'] += seg['duration']
                    
                    st.write("**í™”ìë³„ í†µê³„:**")
                    for speaker, stats in speakers.items():
                        st.write(f"- {speaker}: {stats['count']}ê°œ êµ¬ê°„, ì´ {format_time(stats['total_duration'])}")
                    
                    # ìë™ìœ¼ë¡œ ìŒì„± ì¸ì‹ ì‹¤í–‰
                    st.info("ğŸ¤ ìë™ìœ¼ë¡œ ìŒì„± ì¸ì‹ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
                    
                    # Whisper ëª¨ë¸ ì´ˆê¸°í™” (tiny ëª¨ë¸ ì‚¬ìš©)
                    if st.session_state.speech_recognizer is None:
                        with st.spinner("Whisper ëª¨ë¸ ë¡œë”© ì¤‘..."):
                            st.session_state.speech_recognizer = SpeechRecognizer("tiny")
                    
                    if st.session_state.speech_recognizer.model is not None:
                        with st.spinner("ğŸ—£ï¸ ìŒì„± ì¸ì‹ ì¤‘... (ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)"):
                            # ì „ì²´ ë¹„ë””ì˜¤ ìŒì„± ì¸ì‹
                            result = st.session_state.speech_recognizer.transcribe_video(
                                st.session_state.video_editor.video_path,
                                language="ko"
                            )
                            
                            if result:
                                st.session_state.full_transcription = result
                                
                                if 'segments' in result:
                                    # ì¸ì‹ëœ í…ìŠ¤íŠ¸ë¥¼ í™”ì ì„¸ê·¸ë¨¼íŠ¸ì— ë§¤í•‘
                                    recognized_segments = []
                                    whisper_segments = result['segments']
                                    
                                    for seg in segments:
                                        seg_copy = seg.copy()
                                        seg_copy['text'] = ""
                                        matched_texts = []
                                        
                                        seg_start = seg['start']
                                        seg_end = seg['end']
                                        
                                        for whisper_seg in whisper_segments:
                                            w_start = whisper_seg['start']
                                            w_end = whisper_seg['end']
                                            
                                            if (w_start < seg_end and w_end > seg_start):
                                                overlap_start = max(w_start, seg_start)
                                                overlap_end = min(w_end, seg_end)
                                                overlap_duration = overlap_end - overlap_start
                                                
                                                if overlap_duration > 0.2 * (w_end - w_start):
                                                    matched_texts.append(whisper_seg['text'].strip())
                                        
                                        seg_copy['text'] = " ".join(matched_texts)
                                        seg_copy['has_text'] = bool(seg_copy['text'])
                                        recognized_segments.append(seg_copy)
                                    
                                    st.session_state.recognized_segments = recognized_segments
                                    
                                    # ì¸ì‹ëœ í…ìŠ¤íŠ¸ ê°œìˆ˜ í™•ì¸
                                    text_count = sum(1 for seg in recognized_segments if seg.get('text', '').strip())
                                    st.success(f"âœ… ìŒì„± ì¸ì‹ ì™„ë£Œ! {text_count}/{len(recognized_segments)}ê°œ êµ¬ê°„ì—ì„œ ìŒì„± ê°ì§€")
                                else:
                                    st.warning("ìŒì„± ì¸ì‹ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                            else:
                                st.error("ìŒì„± ì¸ì‹ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                    else:
                        st.error("Whisper ëª¨ë¸ ë¡œë”©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                else:
                    st.warning("í™”ì êµ¬ê°„ì„ ê°ì§€í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        
        # í™”ì êµ¬ê°„ì´ ê°ì§€ëœ ê²½ìš°
        if 'speaker_segments' in st.session_state and st.session_state.speaker_segments:
            st.markdown("---")
            
            # í™”ìë³„ í”„ë¡œí•„ ìƒì„± ë° í‘œì‹œ
            st.subheader("ğŸ‘¥ í™”ìë³„ í”„ë¡œí•„")
            
            # í™”ìë³„ í”„ë¡œí•„ ì •ë³´ ìƒì„±
            speaker_profiles = st.session_state.video_editor.generate_speaker_profile(st.session_state.speaker_segments)
            
            if speaker_profiles:
                # íƒ­ìœ¼ë¡œ í”„ë¡œí•„ê³¼ ìƒì„¸ ì •ë³´ ë¶„ë¦¬
                profile_tab, detail_tab, transcript_tab = st.tabs(["ğŸ‘¤ í”„ë¡œí•„", "ğŸ“Š ìƒì„¸ í†µê³„", "ğŸ“ ìŒì„± ì¸ì‹"])
                
                with profile_tab:
                    # í™”ìë³„ í”„ë¡œí•„ ì¹´ë“œ í‘œì‹œ
                    speakers = list(speaker_profiles.keys())
                    cols = st.columns(min(len(speakers), 3))  # ìµœëŒ€ 3ì—´ë¡œ í‘œì‹œ
                    
                    for i, speaker_id in enumerate(speakers):
                        with cols[i % 3]:
                            profile = speaker_profiles[speaker_id]
                            
                            # í”„ë¡œí•„ ì¹´ë“œ
                            with st.container():
                                st.markdown(f"### {speaker_id}")
                                
                                # ì¸ë„¤ì¼ í‘œì‹œ
                                if profile['has_thumbnail']:
                                    thumbnail = profile['thumbnail']
                                    st.image(
                                        f"data:image/jpeg;base64,{thumbnail['image_base64']}",
                                        caption=f"íƒ€ì„ìŠ¤íƒ¬í”„: {format_time(thumbnail['timestamp'])}",
                                        width=150
                                    )
                                else:
                                    st.info("ì¸ë„¤ì¼ ìƒì„± ì‹¤íŒ¨")
                                
                                # ìš”ì•½ ì •ë³´ í‘œì‹œ
                                if profile['has_summary']:
                                    summary = profile['summary']
                                    st.metric("ì´ ë°œí™” ì‹œê°„", f"{format_time(summary['total_duration'])}")
                                    st.metric("ë°œí™” íšŸìˆ˜", f"{summary['segment_count']}íšŒ")
                                    st.metric("ì°¸ì—¬ìœ¨", f"{summary['participation_rate']}%")
                                    
                                    # ì²« ë“±ì¥ ì‹œê°„
                                    st.write(f"**ì²« ë“±ì¥:** {format_time(summary['first_appearance'])}")
                                    st.write(f"**ë§ˆì§€ë§‰ ë“±ì¥:** {format_time(summary['last_appearance'])}")
                                
                                st.markdown("---")
                
                with detail_tab:
                    st.write("**í™”ìë³„ ìƒì„¸ í†µê³„:**")
                    
                    # í†µê³„ í…Œì´ë¸” ìƒì„±
                    stats_data = []
                    for speaker_id, profile in speaker_profiles.items():
                        if profile['has_summary']:
                            summary = profile['summary']
                            stats_data.append({
                                'í™”ì': speaker_id,
                                'ì´ ë°œí™” ì‹œê°„': format_time(summary['total_duration']),
                                'ë°œí™” íšŸìˆ˜': summary['segment_count'],
                                'í‰ê·  ë°œí™” ê¸¸ì´': format_time(summary['avg_duration']),
                                'ì°¸ì—¬ìœ¨ (%)': summary['participation_rate'],
                                'ì²« ë“±ì¥': format_time(summary['first_appearance']),
                                'ë§ˆì§€ë§‰ ë“±ì¥': format_time(summary['last_appearance'])
                            })
                    
                    if stats_data:
                        st.dataframe(stats_data, use_container_width=True)
                
                with transcript_tab:
                    st.write("**ìŒì„± ì¸ì‹ ë° ë‚´ìš© ìš”ì•½**")
                    
                    # ìŒì„± ì¸ì‹ ì´ˆê¸°í™” í™•ì¸
                    if st.session_state.speech_recognizer is None:
                        st.info("ìŒì„± ì¸ì‹ ê¸°ëŠ¥ì„ ì´ˆê¸°í™”í•˜ë ¤ë©´ ì•„ë˜ ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.")
                        
                        col1, col2 = st.columns([1, 2])
                        with col1:
                            model_size = st.selectbox(
                                "Whisper ëª¨ë¸ í¬ê¸°",
                                ["tiny", "base", "small", "medium"],
                                index=1,
                                help="tiny: ë¹ ë¦„/ë‚®ì€ ì •í™•ë„, base: ê· í˜•, small: ë†’ì€ ì •í™•ë„, medium: ìµœê³  ì •í™•ë„/ëŠë¦¼"
                            )
                        
                        if st.button("ìŒì„± ì¸ì‹ ì´ˆê¸°í™”", type="primary"):
                            with st.spinner("Whisper ëª¨ë¸ì„ ë¡œë”©í•˜ëŠ” ì¤‘..."):
                                st.session_state.speech_recognizer = SpeechRecognizer(model_size)
                                if st.session_state.speech_recognizer.model is not None:
                                    st.success("ìŒì„± ì¸ì‹ê¸°ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")
                                    st.rerun()
                                else:
                                    st.error("ìŒì„± ì¸ì‹ê¸° ì´ˆê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                    
                    else:
                        # ìŒì„± ì¸ì‹ ì‹¤í–‰ ì˜µì…˜
                        col1, col2 = st.columns(2)
                        with col1:
                            language = st.selectbox(
                                "ì–¸ì–´ ì„ íƒ",
                                ["ko", "en", "auto"],
                                index=0,
                                help="ko: í•œêµ­ì–´, en: ì˜ì–´, auto: ìë™ ê°ì§€"
                            )
                        
                        with col2:
                            include_summary = st.checkbox("ëŒ€í™” ë‚´ìš© ìš”ì•½ í¬í•¨", value=True)
                        
                        if st.button("ìŒì„± ì¸ì‹ ì‹¤í–‰", type="primary"):
                            with st.spinner("ìŒì„± ì¸ì‹ì„ ì‹¤í–‰í•˜ëŠ” ì¤‘..."):
                                # í™”ìë³„ ì„¸ê·¸ë¨¼íŠ¸ì— ìŒì„± ì¸ì‹ ì ìš©
                                recognized_segments = st.session_state.speech_recognizer.transcribe_segments(
                                    st.session_state.video_editor.video_path,
                                    st.session_state.speaker_segments,
                                    language=language
                                )
                                
                                if recognized_segments:
                                    st.session_state.recognized_segments = recognized_segments
                                    st.success("ìŒì„± ì¸ì‹ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
                                else:
                                    st.error("ìŒì„± ì¸ì‹ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                        
                        # ìŒì„± ì¸ì‹ ê²°ê³¼ í‘œì‹œ
                        if 'recognized_segments' in st.session_state:
                            st.markdown("### ğŸ“ ìŒì„± ì¸ì‹ ê²°ê³¼")
                            
                            # í™”ìë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ í‘œì‹œ
                            recognized_by_speaker = {}
                            for segment in st.session_state.recognized_segments:
                                speaker = segment['speaker']
                                if speaker not in recognized_by_speaker:
                                    recognized_by_speaker[speaker] = []
                                recognized_by_speaker[speaker].append(segment)
                            
                            for speaker_id, segments in recognized_by_speaker.items():
                                with st.expander(f"{speaker_id} ë°œí™” ë‚´ìš©", expanded=True):
                                    for i, segment in enumerate(segments):
                                        if segment.get('has_text', False):
                                            st.write(f"**{format_time(segment['start'])} - {format_time(segment['end'])}**")
                                            st.write(f"ğŸ—£ï¸ {segment['text']}")
                                            st.markdown("---")
                                        else:
                                            st.write(f"**{format_time(segment['start'])} - {format_time(segment['end'])}**: *ìŒì„± ì¸ì‹ ê²°ê³¼ ì—†ìŒ*")
                            
                            # ëŒ€í™” ìš”ì•½ ìƒì„±
                            if include_summary:
                                st.markdown("### ğŸ“‹ ëŒ€í™” ìš”ì•½")
                                
                                analyzer = AdvancedSpeechAnalyzer(st.session_state.speech_recognizer)
                                meeting_summary = analyzer.generate_meeting_summary(st.session_state.recognized_segments)
                                
                                if meeting_summary:
                                    st.text_area(
                                        "ì¢…í•© ìš”ì•½",
                                        meeting_summary,
                                        height=300,
                                        disabled=True
                                    )
                                
                                # ëŒ€í™” íë¦„ ë¶„ì„
                                conversation_analysis = analyzer.analyze_conversation_flow(st.session_state.recognized_segments)
                                
                                if conversation_analysis.get('timeline'):
                                    st.markdown("### ğŸ•’ ëŒ€í™” íƒ€ì„ë¼ì¸")
                                    
                                    timeline_data = []
                                    for item in conversation_analysis['timeline']:
                                        timeline_data.append({
                                            'ì‹œê°„': format_time(item['time']),
                                            'í™”ì': item['speaker'],
                                            'ë‚´ìš©': item['text'],
                                            'ê¸¸ì´': format_time(item['duration'])
                                        })
                                    
                                    st.dataframe(timeline_data, use_container_width=True)
            
            st.markdown("---")
            st.subheader("ğŸ¬ ì „ì²´ ëŒ€í™” íƒ€ì„ë¼ì¸")
            
            # ì‹œê°„ìˆœìœ¼ë¡œ ì •ë ¬
            sorted_segments = sorted(st.session_state.speaker_segments, key=lambda x: x['start'])
            
            # í™”ìë³„ í”„ë¡œí•„ ì •ë³´ ìƒì„± (ì¸ë„¤ì¼ í¬í•¨)
            all_profiles = st.session_state.video_editor.generate_speaker_profile(sorted_segments)
            
            # ìŒì„± ì¸ì‹ì´ ìˆëŠ” ê²½ìš° í…ìŠ¤íŠ¸ ë§¤í•‘
            segment_texts = {}
            if 'recognized_segments' in st.session_state:
                for rec_seg in st.session_state.recognized_segments:
                    key = f"{rec_seg['start']:.1f}_{rec_seg['end']:.1f}"
                    segment_texts[key] = rec_seg.get('text', '')
            
            # ì „ì²´ íƒ€ì„ë¼ì¸ í‘œì‹œ
            st.info(f"ğŸ“Š ì´ {len(sorted_segments)}ê°œì˜ ë°œí™” êµ¬ê°„")
            
            # ì„¸ê·¸ë¨¼íŠ¸ë¥¼ í–‰ë‹¹ 4ê°œì”© í‘œì‹œ
            cols_per_row = 4
            for i in range(0, len(sorted_segments), cols_per_row):
                cols = st.columns(cols_per_row)
                
                for j, seg in enumerate(sorted_segments[i:i+cols_per_row]):
                    if j < len(cols):
                        with cols[j]:
                            # ì¸ë„¤ì¼ ìƒì„±
                            try:
                                if st.session_state.video_editor.video_clip:
                                    mid_time = (seg['start'] + seg['end']) / 2
                                    frame = st.session_state.video_editor.video_clip.get_frame(mid_time)
                                    
                                    from PIL import Image
                                    import base64
                                    import io
                                    
                                    pil_image = Image.fromarray(frame)
                                    pil_image.thumbnail((200, 150), Image.Resampling.LANCZOS)
                                    
                                    # Base64 ì¸ì½”ë”©
                                    buffer = io.BytesIO()
                                    pil_image.save(buffer, format='JPEG', quality=85)
                                    img_str = base64.b64encode(buffer.getvalue()).decode()
                                    
                                    # ì¸ë„¤ì¼ í‘œì‹œ
                                    st.image(f"data:image/jpeg;base64,{img_str}", use_container_width=True)
                            except:
                                st.image("https://via.placeholder.com/200x150?text=No+Thumbnail", use_container_width=True)
                            
                            # í™”ì ì •ë³´
                            speaker_color = {
                                'SPEAKER_0': 'ğŸ”´',
                                'SPEAKER_1': 'ğŸ”µ', 
                                'SPEAKER_2': 'ğŸŸ¢',
                                'SPEAKER_3': 'ğŸŸ¡',
                                'SPEAKER_4': 'ğŸŸ£',
                                'SPEAKER_5': 'ğŸŸ¤'
                            }
                            
                            speaker_emoji = speaker_color.get(seg['speaker'], 'âšª')
                            st.markdown(f"### {speaker_emoji} {seg['speaker']}")
                            
                            # ì‹œê°„ ì •ë³´
                            st.caption(f"â±ï¸ {format_time(seg['start'])} - {format_time(seg['end'])}")
                            st.caption(f"ğŸ“ ê¸¸ì´: {format_time(seg['duration'])}")
                            
                            # í…ìŠ¤íŠ¸/ìš”ì•½
                            seg_key = f"{seg['start']:.1f}_{seg['end']:.1f}"
                            text = segment_texts.get(seg_key, '')
                            
                            # recognized_segmentsì—ì„œ ì§ì ‘ ì°¾ê¸°
                            if not text and 'recognized_segments' in st.session_state:
                                for rec_seg in st.session_state.recognized_segments:
                                    if (abs(rec_seg['start'] - seg['start']) < 1.0 and 
                                        abs(rec_seg['end'] - seg['end']) < 1.0):
                                        text = rec_seg.get('text', '').strip()
                                        break
                            
                            if text:
                                # í…ìŠ¤íŠ¸ ê¸¸ì´ í™•ì¸
                                text_length = len(text)
                                
                                # Geminië¡œ ìš”ì•½ ì‹œë„ (ì„ê³„ê°’ 50ìë¡œ ë‚®ì¶¤)
                                if GEMINI_AVAILABLE and st.session_state.gemini_summarizer is not None:
                                    try:
                                        if text_length > 50:
                                            # Gemini ìš”ì•½ ì‹œë„ (ê¸¸ì´ ëŠ˜ë¦¼)
                                            summary = st.session_state.gemini_summarizer.summarize_text(text, 150)
                                            st.info(f"ğŸ’¬ {summary}")
                                            st.caption(f"âœ… Gemini ìš”ì•½ ì™„ë£Œ | ì›ë³¸: {text_length}ì")
                                        else:
                                            # ì§§ì€ í…ìŠ¤íŠ¸ëŠ” ê·¸ëŒ€ë¡œ í‘œì‹œ
                                            st.info(f"ğŸ’¬ {text}")
                                            st.caption(f"ì›ë³¸ í…ìŠ¤íŠ¸ | {text_length}ì")
                                    except Exception as e:
                                        # ì—ëŸ¬ ë°œìƒ ì‹œ ë” ë‚˜ì€ ê¸°ë³¸ ìš”ì•½
                                        st.warning(f"âš ï¸ Gemini ìš”ì•½ ì‹¤íŒ¨: {str(e)}")
                                        # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë” ë‚˜ì€ ê¸°ë³¸ ìš”ì•½
                                        sentences = text.replace('?', '.').replace('!', '.').split('.')
                                        sentences = [s.strip() for s in sentences if s.strip()]
                                        if sentences:
                                            summary = sentences[0]
                                            if len(summary) > 80:
                                                summary = summary[:80] + "..."
                                        else:
                                            summary = text[:80] + "..." if text_length > 80 else text
                                        st.info(f"ğŸ’¬ {summary}")
                                        st.caption(f"ê¸°ë³¸ ìš”ì•½ (Gemini ì˜¤ë¥˜) | ì›ë³¸: {text_length}ì")
                                else:
                                    # Gemini ì‚¬ìš© ë¶ˆê°€ ì‹œ ë” ë‚˜ì€ ê¸°ë³¸ ìš”ì•½
                                    sentences = text.replace('?', '.').replace('!', '.').split('.')
                                    sentences = [s.strip() for s in sentences if s.strip()]
                                    if sentences and len(sentences) > 1:
                                        # ì²« ë¬¸ì¥ + í‚¤ì›Œë“œ
                                        summary = sentences[0]
                                        if len(summary) > 60:
                                            summary = summary[:60] + "..."
                                        st.info(f"ğŸ’¬ {summary}")
                                        st.caption(f"ê¸°ë³¸ ìš”ì•½ | ì›ë³¸: {text_length}ì")
                                    else:
                                        # í…ìŠ¤íŠ¸ê°€ ì§§ê±°ë‚˜ ë¬¸ì¥ ë¶„ë¦¬ ì‹¤íŒ¨
                                        summary = text[:80] + "..." if text_length > 80 else text
                                        st.info(f"ğŸ’¬ {summary}")
                                        st.caption(f"ì›ë³¸ í…ìŠ¤íŠ¸ | {text_length}ì")
                            else:
                                st.caption("ğŸ”‡ ìŒì„± ì¸ì‹ í•„ìš”")
                            
                            # êµ¬ë¶„ì„ 
                            st.markdown("---")
                    
            # ìŒì„± ì¸ì‹ ë²„íŠ¼ ì¶”ê°€
            st.markdown("---")
            
            # ì „ì²´ ìŒì„± ì¸ì‹ ê²°ê³¼ í‘œì‹œ (í™”ì êµ¬ë¶„ ì—†ì´)
            if 'full_transcription' in st.session_state and st.session_state.full_transcription:
                with st.expander("ğŸ“ ì „ì²´ ìŒì„± ì¸ì‹ ê²°ê³¼", expanded=True):
                    full_text = st.session_state.full_transcription.get('text', '')
                    
                    # ì „ì²´ í…ìŠ¤íŠ¸ ìš”ì•½ ìƒì„±
                    if full_text and len(full_text.strip()) > 100:
                        # ìš”ì•½ í—¤ë”ì™€ ë²„íŠ¼
                        col1, col2 = st.columns([3, 1])
                        with col1:
                            st.subheader("ğŸ“‹ ì „ì²´ ëŒ€í™” ìš”ì•½")
                        with col2:
                            if st.button("ğŸ”„ ìš”ì•½ ìƒˆë¡œê³ ì¹¨", key="refresh_summary"):
                                # ìš”ì•½ ìºì‹œ ì‚­ì œí•˜ê³  ìƒˆë¡œê³ ì¹¨
                                if 'summary_cache' in st.session_state:
                                    del st.session_state.summary_cache
                                st.rerun()
                        
                        # Geminië¡œ ì „ì²´ ìš”ì•½ ì‹œë„
                        if GEMINI_AVAILABLE and st.session_state.gemini_summarizer is not None:
                            try:
                                # ì „ì²´ ëŒ€í™” ìš”ì•½ (ë” ê¸´ ìš”ì•½)
                                full_summary = st.session_state.gemini_summarizer.summarize_text(full_text, 200)
                                st.success("âœ… **AI ìš”ì•½ ì™„ë£Œ:**")
                                st.info(full_summary)
                                
                                # í‚¤ì›Œë“œ ì¶”ì¶œ
                                keywords = st.session_state.gemini_summarizer.extract_keywords(full_text, 8)
                                if keywords:
                                    st.write("âœ… **í‚¤ì›Œë“œ ì¶”ì¶œ ì™„ë£Œ:**")
                                    keyword_tags = " ".join([f"`{kw}`" for kw in keywords])
                                    st.markdown(keyword_tags)
                                
                            except Exception as e:
                                st.warning(f"âš ï¸ AI ìš”ì•½ ì‹¤íŒ¨: {str(e)}")
                                # ê¸°ë³¸ ìš”ì•½
                                sentences = full_text.replace('?', '.').replace('!', '.').split('.')
                                sentences = [s.strip() for s in sentences if s.strip()]
                                if len(sentences) > 3:
                                    summary = '. '.join(sentences[:3]) + '.'
                                else:
                                    summary = full_text[:200] + "..."
                                st.info(f"ğŸ“ **ê¸°ë³¸ ìš”ì•½:** {summary}")
                        else:
                            # Gemini ì‚¬ìš© ë¶ˆê°€ ì‹œ ê¸°ë³¸ ìš”ì•½
                            sentences = full_text.replace('?', '.').replace('!', '.').split('.')
                            sentences = [s.strip() for s in sentences if s.strip()]
                            if len(sentences) > 3:
                                summary = '. '.join(sentences[:3]) + '.'
                            else:
                                summary = full_text[:200] + "..."
                            st.info(f"ğŸ“ **ê¸°ë³¸ ìš”ì•½:** {summary}")
                        
                        # í†µê³„ ì •ë³´
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("ì´ ê¸€ì ìˆ˜", f"{len(full_text):,}ì")
                        with col2:
                            word_count = len(full_text.split())
                            st.metric("ì´ ë‹¨ì–´ ìˆ˜", f"{word_count:,}ê°œ")
                        with col3:
                            if 'segments' in st.session_state.full_transcription:
                                seg_count = len(st.session_state.full_transcription['segments'])
                                st.metric("ìŒì„± ì„¸ê·¸ë¨¼íŠ¸", f"{seg_count}ê°œ")
                        
                        st.markdown("---")
                    
                    # í™”ìë³„ ì¢…í•© ë¶„ì„ (ìŒì„± ì¸ì‹ëœ ì„¸ê·¸ë¨¼íŠ¸ê°€ ìˆëŠ” ê²½ìš°)
                    if 'recognized_segments' in st.session_state and st.session_state.recognized_segments:
                        st.subheader("ğŸ‘¥ í™”ìë³„ ëŒ€í™” ë¶„ì„")
                        
                        # Geminië¡œ íšŒì˜/ëŒ€í™” ì¢…í•© ìš”ì•½
                        if GEMINI_AVAILABLE and st.session_state.gemini_summarizer is not None:
                            try:
                                # í™”ìë³„ ì„¸ê·¸ë¨¼íŠ¸ ì¤€ë¹„
                                segments_for_analysis = []
                                for seg in st.session_state.recognized_segments:
                                    if seg.get('text', '').strip():
                                        segments_for_analysis.append({
                                            'speaker': seg['speaker'],
                                            'text': seg['text'],
                                            'start': seg['start'],
                                            'end': seg['end']
                                        })
                                
                                if segments_for_analysis:
                                    # í™”ìë³„ ìš”ì•½ (íšŒì˜ ë¶„ì„ ëŒ€ì‹  í™”ìë³„ ë¶„ì„ìœ¼ë¡œ ë³€ê²½)
                                    speaker_summaries = st.session_state.gemini_summarizer.summarize_conversation(segments_for_analysis)
                                    if speaker_summaries:
                                        st.write("**âœ… í™”ìë³„ ë°œì–¸ ìš”ì•½ ì™„ë£Œ:**")
                                        for speaker, summary in speaker_summaries.items():
                                            if summary and summary != "ë°œí™” ë‚´ìš© ì—†ìŒ":
                                                st.write(f"**ğŸ¤ {speaker}:**")
                                                st.info(summary)
                                
                            except Exception as e:
                                st.warning(f"âš ï¸ í™”ìë³„ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
                        
                        st.markdown("---")
                    
            
            # ì „ì²´ í…ìŠ¤íŠ¸ ì›ë³¸ (ë³„ë„ expander)
            if 'full_transcription' in st.session_state and st.session_state.full_transcription:
                full_text = st.session_state.full_transcription.get('text', '')
                if full_text:
                    with st.expander("ğŸ“„ ì „ì²´ í…ìŠ¤íŠ¸ ì›ë³¸", expanded=False):
                        st.write("**ì „ì²´ í…ìŠ¤íŠ¸:**")
                        st.text_area("", full_text, height=200, disabled=True)
                    
                    # ì„¸ê·¸ë¨¼íŠ¸ë³„ ìƒì„¸ (ë³„ë„ expander)
                    if 'segments' in st.session_state.full_transcription:
                        with st.expander(f"ğŸ” ì„¸ê·¸ë¨¼íŠ¸ë³„ ìƒì„¸ ({len(st.session_state.full_transcription['segments'])}ê°œ)", expanded=False):
                            for i, seg in enumerate(st.session_state.full_transcription['segments']):
                                st.write(f"{i+1}. [{seg['start']:.1f}s - {seg['end']:.1f}s]: {seg['text']}")
            
            # Gemini API ìƒíƒœ í™•ì¸ (ë³„ë„ expander)
            with st.expander("ğŸ¤– Gemini API ìƒíƒœ", expanded=False):
                st.write(f"**Gemini ì‚¬ìš© ê°€ëŠ¥:** {'âœ… Yes' if GEMINI_AVAILABLE else 'âŒ No'}")
                if GEMINI_AVAILABLE:
                    st.write(f"**Gemini ì´ˆê¸°í™”:** {'âœ… Yes' if st.session_state.gemini_summarizer is not None else 'âŒ No'}")
                    
                    if st.session_state.gemini_summarizer is not None:
                        # Gemini í…ŒìŠ¤íŠ¸
                        if st.button("ğŸ§ª Gemini í…ŒìŠ¤íŠ¸", key="test_gemini"):
                            try:
                                test_text = "ì´ê²ƒì€ Gemini API í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ê¸´ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ì—¬ëŸ¬ ë¬¸ì¥ì„ í¬í•¨í•˜ê³  ìˆìœ¼ë©°, APIê°€ ì œëŒ€ë¡œ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸í•˜ê¸° ìœ„í•œ ëª©ì ìœ¼ë¡œ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ í…ìŠ¤íŠ¸ê°€ ì œëŒ€ë¡œ ìš”ì•½ë˜ë©´ Gemini APIê°€ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤."
                                result = st.session_state.gemini_summarizer.summarize_text(test_text, 50)
                                st.success("âœ… Gemini API í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
                                st.write(f"**ì›ë³¸:** {test_text}")
                                st.write(f"**ìš”ì•½:** {result}")
                            except Exception as e:
                                st.error(f"âŒ Gemini API ì˜¤ë¥˜: {str(e)}")
                else:
                    st.info("Gemini APIë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ google-generativeai íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
                    st.code("pip install google-generativeai")
            
            # ìŒì„± ì¸ì‹ ë””ë²„ê·¸ ì˜µì…˜
            with st.expander("ğŸ”§ ìŒì„± ì¸ì‹ ë””ë²„ê·¸", expanded=False):
                if st.button("ğŸ§ª ìŒì„± ì¸ì‹ í…ŒìŠ¤íŠ¸ (ì²« 30ì´ˆ)", key="test_whisper"):
                    with st.spinner("í…ŒìŠ¤íŠ¸ ì¤‘..."):
                        if st.session_state.speech_recognizer is None:
                            st.session_state.speech_recognizer = SpeechRecognizer("tiny")
                        
                        # ë¹„ë””ì˜¤ ê²½ë¡œ í™•ì¸
                        video_path = st.session_state.video_editor.video_path
                        st.write(f"ë¹„ë””ì˜¤ ê²½ë¡œ: {video_path}")
                        
                        # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ - ì²« 30ì´ˆë§Œ
                        try:
                            import tempfile
                            from moviepy.editor import VideoFileClip
                            
                            # ì²« 30ì´ˆë§Œ ì¶”ì¶œ
                            with VideoFileClip(video_path) as video:
                                test_duration = min(30, video.duration)
                                subclip = video.subclip(0, test_duration)
                                
                                # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
                                temp_path = tempfile.mktemp(suffix='.mp4')
                                subclip.write_videofile(temp_path, verbose=False, logger=None)
                                
                                # Whisper í…ŒìŠ¤íŠ¸
                                result = st.session_state.speech_recognizer.transcribe_video(temp_path, language="ko")
                                
                                if result and 'text' in result:
                                    st.success("âœ… ìŒì„± ì¸ì‹ ì„±ê³µ!")
                                    st.write("ì „ì²´ í…ìŠ¤íŠ¸:", result['text'])
                                    
                                    if 'segments' in result:
                                        st.write(f"ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜: {len(result['segments'])}")
                                        for i, seg in enumerate(result['segments'][:5]):  # ì²« 5ê°œë§Œ
                                            st.write(f"{i+1}. [{seg['start']:.1f}s - {seg['end']:.1f}s]: {seg['text']}")
                                else:
                                    st.error("âŒ ìŒì„± ì¸ì‹ ì‹¤íŒ¨: í…ìŠ¤íŠ¸ ì—†ìŒ")
                                
                                # ì„ì‹œ íŒŒì¼ ì‚­ì œ
                                import os
                                if os.path.exists(temp_path):
                                    os.remove(temp_path)
                                    
                        except Exception as e:
                            st.error(f"í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")
                            import traceback
                            st.code(traceback.format_exc())
            
            # ìˆ˜ë™ ìŒì„± ì¸ì‹ ì˜µì…˜ (ì´ë¯¸ ìë™ ì‹¤í–‰ëœ ê²½ìš° í‘œì‹œ)
            if 'recognized_segments' in st.session_state and st.session_state.recognized_segments:
                st.success("âœ… ìŒì„± ì¸ì‹ì´ ì´ë¯¸ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
                
                # ì¬ì‹¤í–‰ ì˜µì…˜
                with st.expander("ğŸ”„ ë‹¤ë¥¸ ëª¨ë¸ë¡œ ì¬ì‹¤í–‰", expanded=False):
                    col1, col2 = st.columns([1, 2])
                    with col1:
                        whisper_model = st.selectbox(
                            "ğŸ™ï¸ Whisper ëª¨ë¸",
                            ["tiny", "base", "small"],
                            index=0,
                            help="tiny: ë¹ ë¦„(39MB), base: ê· í˜•(74MB), small: ì •í™•(244MB)"
                        )
                    
                    if st.button("ğŸ”„ ìŒì„± ì¸ì‹ ì¬ì‹¤í–‰", type="secondary", key="rerun_whisper"):
                        # ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼í•œ ìŒì„± ì¸ì‹ ë¡œì§
                        try:
                            with st.spinner(f"Whisper {whisper_model} ëª¨ë¸ ë¡œë”© ì¤‘..."):
                                if st.session_state.speech_recognizer is None or st.session_state.speech_recognizer.model_size != whisper_model:
                                    st.session_state.speech_recognizer = SpeechRecognizer(whisper_model)
                                
                                if st.session_state.speech_recognizer.model is not None:
                                    # ì§„í–‰ ìƒí™© í‘œì‹œ
                                    progress_bar = st.progress(0)
                                    status_text = st.empty()
                                    
                                    # ì „ì²´ ë¹„ë””ì˜¤ ìŒì„± ì¸ì‹
                                    status_text.text("ğŸµ ì˜¤ë””ì˜¤ ì¶”ì¶œ ì¤‘...")
                                    progress_bar.progress(10)
                                    
                                    # ì§ì ‘ ì „ì²´ ë¹„ë””ì˜¤ ìŒì„± ì¸ì‹ ì‹¤í–‰
                                    status_text.text("ğŸ—£ï¸ ìŒì„± ì¸ì‹ ì¤‘... (ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
                                    progress_bar.progress(30)
                                    
                                    result = st.session_state.speech_recognizer.transcribe_video(
                                        st.session_state.video_editor.video_path,
                                        language="ko"
                                    )
                                    
                                    progress_bar.progress(80)
                                    
                                    # ì „ì²´ ìŒì„± ì¸ì‹ ê²°ê³¼ ì €ì¥
                                    if result:
                                        st.session_state.full_transcription = result
                                    
                                    if result and 'segments' in result:
                                        # ì¸ì‹ëœ í…ìŠ¤íŠ¸ë¥¼ í™”ì ì„¸ê·¸ë¨¼íŠ¸ì— ë§¤í•‘
                                        recognized_segments = []
                                        whisper_segments = result['segments']
                                        
                                        # ë””ë²„ê·¸ ì •ë³´
                                        st.write(f"ğŸ¯ Whisper ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜: {len(whisper_segments)}")
                                        st.write(f"ğŸ¯ í™”ì ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜: {len(sorted_segments)}")
                                        
                                        for seg in sorted_segments:
                                            seg_copy = seg.copy()
                                            seg_copy['text'] = ""
                                            matched_texts = []
                                            
                                            # í•´ë‹¹ ì‹œê°„ëŒ€ì˜ í…ìŠ¤íŠ¸ ì°¾ê¸° (ë” ìœ ì—°í•œ ë§¤ì¹­)
                                            seg_start = seg['start']
                                            seg_end = seg['end']
                                            
                                            for whisper_seg in whisper_segments:
                                                w_start = whisper_seg['start']
                                                w_end = whisper_seg['end']
                                                
                                                # ì‹œê°„ ë²”ìœ„ê°€ ê²¹ì¹˜ëŠ”ì§€ í™•ì¸ (ë” ê´€ëŒ€í•œ ì¡°ê±´)
                                                if (w_start < seg_end and w_end > seg_start):
                                                    # ê²¹ì¹˜ëŠ” ë¹„ìœ¨ ê³„ì‚°
                                                    overlap_start = max(w_start, seg_start)
                                                    overlap_end = min(w_end, seg_end)
                                                    overlap_duration = overlap_end - overlap_start
                                                    
                                                    # 20% ì´ìƒ ê²¹ì¹˜ë©´ í¬í•¨
                                                    if overlap_duration > 0.2 * (w_end - w_start):
                                                        matched_texts.append(whisper_seg['text'].strip())
                                            
                                            seg_copy['text'] = " ".join(matched_texts)
                                            seg_copy['has_text'] = bool(seg_copy['text'])
                                            recognized_segments.append(seg_copy)
                                        
                                        # ë§¤ì¹­ ê²°ê³¼ í™•ì¸
                                        matched_count = sum(1 for s in recognized_segments if s['has_text'])
                                        st.write(f"ğŸ¯ ë§¤ì¹­ëœ ì„¸ê·¸ë¨¼íŠ¸: {matched_count}/{len(recognized_segments)}")
                                        
                                        st.session_state.recognized_segments = recognized_segments
                                        
                                        # ì¸ì‹ëœ í…ìŠ¤íŠ¸ ê°œìˆ˜ í™•ì¸
                                        text_count = sum(1 for seg in recognized_segments if seg.get('text', '').strip())
                                        progress_bar.progress(100)
                                        st.success(f"âœ… ìŒì„± ì¸ì‹ ì™„ë£Œ! {text_count}/{len(recognized_segments)}ê°œ êµ¬ê°„ì—ì„œ ìŒì„± ê°ì§€")
                                        status_text.text("")
                                        st.rerun()
                                    else:
                                        st.error("âŒ ìŒì„± ì¸ì‹ ì‹¤íŒ¨: í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                                else:
                                    st.error("âŒ Whisper ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨")
                        except Exception as e:
                            st.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                            st.info("ğŸ’¡ íŒ: ë” ì‘ì€ ëª¨ë¸(tiny)ì„ ì‹œë„í•´ë³´ì„¸ìš”")
            else:
                # ìŒì„± ì¸ì‹ì´ ì•„ì§ ì•ˆ ëœ ê²½ìš° (ìë™ ì‹¤í–‰ì´ ì‹¤íŒ¨í–ˆê±°ë‚˜ ì•„ì§ í™”ì ê°ì§€ë¥¼ ì•ˆ í•œ ê²½ìš°)
                st.warning("âš ï¸ ìŒì„± ì¸ì‹ì´ ì•„ì§ ì‹¤í–‰ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                
                # Whisper ëª¨ë¸ ì„ íƒ
                col1, col2 = st.columns([1, 2])
                with col1:
                    whisper_model = st.selectbox(
                        "ğŸ™ï¸ Whisper ëª¨ë¸",
                        ["tiny", "base", "small"],
                        index=0,
                        help="tiny: ë¹ ë¦„(39MB), base: ê· í˜•(74MB), small: ì •í™•(244MB)"
                    )
                
                if st.button("ğŸ¤ ìŒì„± ì¸ì‹ ì‹¤í–‰", type="primary", key="run_whisper"):
                    try:
                        with st.spinner(f"Whisper {whisper_model} ëª¨ë¸ ë¡œë”© ì¤‘..."):
                            if st.session_state.speech_recognizer is None or st.session_state.speech_recognizer.model_size != whisper_model:
                                st.session_state.speech_recognizer = SpeechRecognizer(whisper_model)
                            
                            if st.session_state.speech_recognizer.model is not None:
                                # ì§„í–‰ ìƒí™© í‘œì‹œ
                                progress_bar = st.progress(0)
                                status_text = st.empty()
                                
                                # ì „ì²´ ë¹„ë””ì˜¤ ìŒì„± ì¸ì‹
                                status_text.text("ğŸµ ì˜¤ë””ì˜¤ ì¶”ì¶œ ì¤‘...")
                                progress_bar.progress(10)
                                
                                # ì§ì ‘ ì „ì²´ ë¹„ë””ì˜¤ ìŒì„± ì¸ì‹ ì‹¤í–‰
                                status_text.text("ğŸ—£ï¸ ìŒì„± ì¸ì‹ ì¤‘... (ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
                                progress_bar.progress(30)
                                
                                result = st.session_state.speech_recognizer.transcribe_video(
                                    st.session_state.video_editor.video_path,
                                    language="ko"
                                )
                                
                                progress_bar.progress(80)
                                
                                # ì „ì²´ ìŒì„± ì¸ì‹ ê²°ê³¼ ì €ì¥
                                if result:
                                    st.session_state.full_transcription = result
                                
                                if result and 'segments' in result:
                                    # ì¸ì‹ëœ í…ìŠ¤íŠ¸ë¥¼ í™”ì ì„¸ê·¸ë¨¼íŠ¸ì— ë§¤í•‘
                                    recognized_segments = []
                                    whisper_segments = result['segments']
                                    
                                    # ë””ë²„ê·¸ ì •ë³´
                                    st.write(f"ğŸ¯ Whisper ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜: {len(whisper_segments)}")
                                    st.write(f"ğŸ¯ í™”ì ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜: {len(sorted_segments)}")
                                    
                                    for seg in sorted_segments:
                                        seg_copy = seg.copy()
                                        seg_copy['text'] = ""
                                        matched_texts = []
                                        
                                        # í•´ë‹¹ ì‹œê°„ëŒ€ì˜ í…ìŠ¤íŠ¸ ì°¾ê¸° (ë” ìœ ì—°í•œ ë§¤ì¹­)
                                        seg_start = seg['start']
                                        seg_end = seg['end']
                                        
                                        for whisper_seg in whisper_segments:
                                            w_start = whisper_seg['start']
                                            w_end = whisper_seg['end']
                                            
                                            # ì‹œê°„ ë²”ìœ„ê°€ ê²¹ì¹˜ëŠ”ì§€ í™•ì¸ (ë” ê´€ëŒ€í•œ ì¡°ê±´)
                                            if (w_start < seg_end and w_end > seg_start):
                                                # ê²¹ì¹˜ëŠ” ë¹„ìœ¨ ê³„ì‚°
                                                overlap_start = max(w_start, seg_start)
                                                overlap_end = min(w_end, seg_end)
                                                overlap_duration = overlap_end - overlap_start
                                                
                                                # 20% ì´ìƒ ê²¹ì¹˜ë©´ í¬í•¨
                                                if overlap_duration > 0.2 * (w_end - w_start):
                                                    matched_texts.append(whisper_seg['text'].strip())
                                        
                                        seg_copy['text'] = " ".join(matched_texts)
                                        seg_copy['has_text'] = bool(seg_copy['text'])
                                        recognized_segments.append(seg_copy)
                                    
                                    # ë§¤ì¹­ ê²°ê³¼ í™•ì¸
                                    matched_count = sum(1 for s in recognized_segments if s['has_text'])
                                    st.write(f"ğŸ¯ ë§¤ì¹­ëœ ì„¸ê·¸ë¨¼íŠ¸: {matched_count}/{len(recognized_segments)}")
                                    
                                    st.session_state.recognized_segments = recognized_segments
                                    
                                    # ì¸ì‹ëœ í…ìŠ¤íŠ¸ ê°œìˆ˜ í™•ì¸
                                    text_count = sum(1 for seg in recognized_segments if seg.get('text', '').strip())
                                    progress_bar.progress(100)
                                    st.success(f"âœ… ìŒì„± ì¸ì‹ ì™„ë£Œ! {text_count}/{len(recognized_segments)}ê°œ êµ¬ê°„ì—ì„œ ìŒì„± ê°ì§€")
                                    status_text.text("")
                                    st.rerun()
                                else:
                                    st.error("âŒ ìŒì„± ì¸ì‹ ì‹¤íŒ¨: í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                            else:
                                st.error("âŒ Whisper ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨")
                    except Exception as e:
                        st.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                        st.info("ğŸ’¡ íŒ: ë” ì‘ì€ ëª¨ë¸(tiny)ì„ ì‹œë„í•´ë³´ì„¸ìš”")
            
            # í™”ìë³„ ìš”ì•½ í†µê³„ í‘œì‹œ
            st.markdown("---")
            st.subheader("ğŸ“Š í™”ìë³„ ìš”ì•½ í†µê³„")
            
            # í™”ìë³„ í†µê³„ ìˆ˜ì§‘
            speaker_stats = {}
            for seg in sorted_segments:
                speaker = seg['speaker']
                if speaker not in speaker_stats:
                    speaker_stats[speaker] = {
                        'count': 0,
                        'total_duration': 0,
                        'segments': []
                    }
                speaker_stats[speaker]['count'] += 1
                speaker_stats[speaker]['total_duration'] += seg['duration']
                speaker_stats[speaker]['segments'].append(seg)
            
            # í™”ìë³„ í†µê³„ ì¹´ë“œ í‘œì‹œ
            stats_cols = st.columns(len(speaker_stats))
            for idx, (speaker, stats) in enumerate(speaker_stats.items()):
                with stats_cols[idx]:
                    speaker_emoji = {
                        'SPEAKER_0': 'ğŸ”´',
                        'SPEAKER_1': 'ğŸ”µ', 
                        'SPEAKER_2': 'ğŸŸ¢',
                        'SPEAKER_3': 'ğŸŸ¡',
                        'SPEAKER_4': 'ğŸŸ£',
                        'SPEAKER_5': 'ğŸŸ¤'
                    }.get(speaker, 'âšª')
                    
                    st.metric(
                        label=f"{speaker_emoji} {speaker}",
                        value=f"{stats['count']}íšŒ",
                        delta=f"{format_time(stats['total_duration'])}"
                    )
                    
                    # ì°¸ì—¬ìœ¨ ê³„ì‚°
                    if st.session_state.video_editor.video_clip:
                        participation = (stats['total_duration'] / st.session_state.video_editor.video_clip.duration) * 100
                        st.caption(f"ì°¸ì—¬ìœ¨: {participation:.1f}%")
            
            # ì „ì²´ ë³€ê²½ì‚¬í•­ ì €ì¥ ë²„íŠ¼
            if st.button("ğŸ”„ ì „ì²´ í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨", type="primary"):
                st.rerun()
            
            st.markdown("---")
            st.write("**í™”ìë³„ ë™ì˜ìƒ ìë¥´ê¸° ì˜µì…˜:**")
            
            col1, col2 = st.columns(2)
            
            with col1:
                if st.button("ëª¨ë“  í™”ì êµ¬ê°„ì„ ê°œë³„ íŒŒì¼ë¡œ ì €ì¥", type="secondary"):
                    with st.spinner("í™”ìë³„ë¡œ ë™ì˜ìƒì„ ìë¥´ëŠ” ì¤‘..."):
                        output_files = st.session_state.video_editor.cut_by_speaker(st.session_state.speaker_segments)
                        
                        if output_files:
                            st.success(f"{len(output_files)}ê°œì˜ ë™ì˜ìƒ íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
                            
                            for file_info in output_files:
                                col_a, col_b = st.columns([3, 1])
                                with col_a:
                                    st.write(f"**{file_info['speaker']}** - {format_time(file_info['start'])} ~ {format_time(file_info['end'])}")
                                with col_b:
                                    with open(file_info['path'], "rb") as file:
                                        st.download_button(
                                            label="ë‹¤ìš´ë¡œë“œ",
                                            data=file,
                                            file_name=f"{file_info['speaker']}_{format_time(file_info['start']).replace(':', '_')}.mp4",
                                            mime="video/mp4",
                                            key=f"download_{file_info['path']}"
                                        )
            
            with col2:
                # íŠ¹ì • í™”ìë§Œ ì„ íƒí•˜ì—¬ í•˜ë‚˜ì˜ íŒŒì¼ë¡œ ë§Œë“¤ê¸°
                speakers_list = list(set(seg['speaker'] for seg in st.session_state.speaker_segments))
                selected_speaker = st.selectbox("íŠ¹ì • í™”ì ì„ íƒ", speakers_list)
                
                if selected_speaker and st.button(f"{selected_speaker}ì˜ ëª¨ë“  êµ¬ê°„ í•©ì¹˜ê¸°", type="secondary"):
                    with st.spinner(f"{selected_speaker}ì˜ êµ¬ê°„ì„ í•©ì¹˜ëŠ” ì¤‘..."):
                        output_path = st.session_state.video_editor.cut_single_speaker(selected_speaker)
                        
                        if output_path:
                            st.success(f"{selected_speaker}ì˜ ëª¨ë“  êµ¬ê°„ì„ í•˜ë‚˜ë¡œ í•©ì³¤ìŠµë‹ˆë‹¤!")
                            st.video(output_path)
                            
                            with open(output_path, "rb") as file:
                                st.download_button(
                                    label=f"{selected_speaker} ì „ì²´ ë™ì˜ìƒ ë‹¤ìš´ë¡œë“œ",
                                    data=file,
                                    file_name=f"{selected_speaker}_combined.mp4",
                                    mime="video/mp4",
                                    key=f"download_combined_{selected_speaker}"
                                )

else:
    st.info("ë™ì˜ìƒ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ í¸ì§‘ì„ ì‹œì‘í•˜ì„¸ìš”.")

if st.button("ì„ì‹œ íŒŒì¼ ì •ë¦¬"):
    temp_dir = Path("temp")
    processed_dir = Path("processed")
    
    if temp_dir.exists():
        shutil.rmtree(temp_dir)
    if processed_dir.exists():
        shutil.rmtree(processed_dir)
    
    st.success("ì„ì‹œ íŒŒì¼ì´ ì •ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
    st.rerun()