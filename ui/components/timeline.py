"""
íƒ€ì„ë¼ì¸ í‘œì‹œ ì»´í¬ë„ŒíŠ¸
"""
import streamlit as st
from PIL import Image
import base64
import io
from typing import List, Dict, Any, Optional
from utils import format_time


# í™”ìë³„ ìƒ‰ìƒ ì´ëª¨ì§€ ë§¤í•‘
SPEAKER_COLORS = {
    'SPEAKER_0': 'ğŸ”´',
    'SPEAKER_1': 'ğŸ”µ', 
    'SPEAKER_2': 'ğŸŸ¢',
    'SPEAKER_3': 'ğŸŸ¡',
    'SPEAKER_4': 'ğŸŸ£',
    'SPEAKER_5': 'ğŸŸ¤'
}


def generate_thumbnail(video_clip, timestamp: float, size: tuple = (200, 150)) -> Optional[str]:
    """
    ë¹„ë””ì˜¤ì—ì„œ ì¸ë„¤ì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        video_clip: MoviePy VideoFileClip ê°ì²´
        timestamp: ì¸ë„¤ì¼ì„ ìƒì„±í•  ì‹œê°„ (ì´ˆ)
        size: ì¸ë„¤ì¼ í¬ê¸° (width, height)
        
    Returns:
        Base64 ì¸ì½”ë”©ëœ ì´ë¯¸ì§€ ë¬¸ìì—´ ë˜ëŠ” None
    """
    try:
        frame = video_clip.get_frame(timestamp)
        pil_image = Image.fromarray(frame)
        pil_image.thumbnail(size, Image.Resampling.LANCZOS)
        
        # Base64 ì¸ì½”ë”©
        buffer = io.BytesIO()
        pil_image.save(buffer, format='JPEG', quality=85)
        img_str = base64.b64encode(buffer.getvalue()).decode()
        
        return img_str
    except Exception:
        return None


def display_timeline_card(
    segment: Dict[str, Any],
    video_clip: Any,
    recognized_text: str = "",
    summarizer: Any = None,
    show_summary: bool = True
):
    """
    íƒ€ì„ë¼ì¸ ì¹´ë“œ í•˜ë‚˜ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.
    
    Args:
        segment: ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´
        video_clip: MoviePy VideoFileClip ê°ì²´
        recognized_text: ìŒì„± ì¸ì‹ëœ í…ìŠ¤íŠ¸
        summarizer: ìš”ì•½ê¸° ê°ì²´ (Gemini/Claude)
        show_summary: ìš”ì•½ í‘œì‹œ ì—¬ë¶€
    """
    # ì¸ë„¤ì¼ ìƒì„± ë° í‘œì‹œ
    mid_time = (segment['start'] + segment['end']) / 2
    thumbnail_base64 = generate_thumbnail(video_clip, mid_time) if video_clip else None
    
    if thumbnail_base64:
        st.image(f"data:image/jpeg;base64,{thumbnail_base64}", use_container_width=True)
    else:
        st.image("https://via.placeholder.com/200x150?text=No+Thumbnail", use_container_width=True)
    
    # í™”ì ì •ë³´
    speaker_emoji = SPEAKER_COLORS.get(segment['speaker'], 'âšª')
    st.markdown(f"### {speaker_emoji} {segment['speaker']}")
    
    # ì‹œê°„ ì •ë³´
    st.caption(f"â±ï¸ {format_time(segment['start'])} - {format_time(segment['end'])}")
    st.caption(f"ğŸ“ ê¸¸ì´: {format_time(segment['duration'])}")
    
    # í…ìŠ¤íŠ¸/ìš”ì•½ í‘œì‹œ
    if recognized_text:
        text_length = len(recognized_text)
        
        if show_summary and summarizer and text_length > 50:
            try:
                # ìš”ì•½ ì‹œë„
                summary = summarizer.summarize_text(recognized_text, 150)
                st.info(f"ğŸ’¬ {summary}")
                st.caption(f"âœ… AI ìš”ì•½ ì™„ë£Œ | ì›ë³¸: {text_length}ì")
            except Exception as e:
                # ìš”ì•½ ì‹¤íŒ¨ ì‹œ ì›ë³¸ í…ìŠ¤íŠ¸ì˜ ì¼ë¶€ í‘œì‹œ
                display_text = recognized_text[:150] + "..." if text_length > 150 else recognized_text
                st.info(f"ğŸ’¬ {display_text}")
                st.caption(f"ì›ë³¸ í…ìŠ¤íŠ¸ | {text_length}ì")
        else:
            # ì§§ì€ í…ìŠ¤íŠ¸ëŠ” ê·¸ëŒ€ë¡œ í‘œì‹œ
            st.info(f"ğŸ’¬ {recognized_text}")
            st.caption(f"ì›ë³¸ í…ìŠ¤íŠ¸ | {text_length}ì")
    else:
        st.info("ğŸ”‡ ìŒì„± ì¸ì‹ ëŒ€ê¸° ì¤‘...")


def display_timeline(
    segments: List[Dict[str, Any]],
    video_clip: Any,
    recognized_segments: Optional[List[Dict[str, Any]]] = None,
    summarizer: Any = None,
    cols_per_row: int = 4
):
    """
    ì „ì²´ íƒ€ì„ë¼ì¸ì„ í‘œì‹œí•©ë‹ˆë‹¤.
    
    Args:
        segments: í™”ì ì„¸ê·¸ë¨¼íŠ¸ ë¦¬ìŠ¤íŠ¸
        video_clip: MoviePy VideoFileClip ê°ì²´
        recognized_segments: ìŒì„± ì¸ì‹ëœ ì„¸ê·¸ë¨¼íŠ¸ ë¦¬ìŠ¤íŠ¸
        summarizer: ìš”ì•½ê¸° ê°ì²´
        cols_per_row: í•œ í–‰ì— í‘œì‹œí•  ì¹´ë“œ ìˆ˜
    """
    st.subheader("ğŸ¬ ì „ì²´ ëŒ€í™” íƒ€ì„ë¼ì¸")
    
    # ì‹œê°„ìˆœìœ¼ë¡œ ì •ë ¬
    sorted_segments = sorted(segments, key=lambda x: x['start'])
    
    # ìŒì„± ì¸ì‹ í…ìŠ¤íŠ¸ ë§¤í•‘
    segment_texts = {}
    if recognized_segments:
        for rec_seg in recognized_segments:
            # ì‹œê°„ ê¸°ë°˜ìœ¼ë¡œ ë§¤ì¹­
            for seg in sorted_segments:
                if (abs(rec_seg['start'] - seg['start']) < 1.0 and 
                    abs(rec_seg['end'] - seg['end']) < 1.0):
                    key = f"{seg['start']:.1f}_{seg['end']:.1f}"
                    segment_texts[key] = rec_seg.get('text', '').strip()
                    break
    
    # ì „ì²´ íƒ€ì„ë¼ì¸ ì •ë³´
    st.info(f"ğŸ“Š ì´ {len(sorted_segments)}ê°œì˜ ë°œí™” êµ¬ê°„")
    
    # ì„¸ê·¸ë¨¼íŠ¸ë¥¼ í–‰ë‹¹ cols_per_rowê°œì”© í‘œì‹œ
    for i in range(0, len(sorted_segments), cols_per_row):
        cols = st.columns(cols_per_row)
        
        for j, seg in enumerate(sorted_segments[i:i+cols_per_row]):
            if j < len(cols):
                with cols[j]:
                    seg_key = f"{seg['start']:.1f}_{seg['end']:.1f}"
                    text = segment_texts.get(seg_key, '')
                    
                    display_timeline_card(
                        segment=seg,
                        video_clip=video_clip,
                        recognized_text=text,
                        summarizer=summarizer
                    )