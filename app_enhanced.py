"""
CutStudio Enhanced - êµìœ¡ íŠ¹í™” ë™ì˜ìƒ í¸ì§‘ê¸°
ê°œì„  ì‚¬í•­:
1. ì›í´ë¦­ í™”ìë³„ ì¶”ì¶œ
2. í™”ì ë¼ë²¨ë§ ì‹œìŠ¤í…œ
3. êµìœ¡ íŠ¹í™” ìš”ì•½
"""

import streamlit as st
from pathlib import Path
import json
from datetime import datetime
from typing import Dict, List, Optional, Tuple
import os

# ë‚´ë¶€ ëª¨ë“ˆ
from core.config import AppConfig
from core.state_manager import StateManager
from services.speaker_detection import UnifiedSpeakerDetector
from services.speech_processing import SpeechProcessor
from services.summarization import SummarizationService
from video_editor import VideoEditor
from utils import (
    get_video_info, format_time, get_mime_type,
    cleanup_old_files, generate_unique_filename
)
from youtube_downloader import YouTubeDownloader

# UI ì»´í¬ë„ŒíŠ¸
from ui.components.speaker_profile import display_speaker_profile
from ui.components.timeline import display_timeline


class EnhancedCutStudioApp:
    """ê°œì„ ëœ CutStudio ì• í”Œë¦¬ì¼€ì´ì…˜"""
    
    def __init__(self):
        """ì• í”Œë¦¬ì¼€ì´ì…˜ ì´ˆê¸°í™”"""
        st.set_page_config(
            page_title="CutStudio Enhanced",
            page_icon="ğŸ¬",
            layout="wide",
            initial_sidebar_state="expanded"
        )
        
        self.config = AppConfig()
        self.state = StateManager()
        self.speaker_detector = UnifiedSpeakerDetector()
        self.speech_processor = SpeechProcessor()
        self.summarizer = SummarizationService()
        self.youtube_downloader = YouTubeDownloader()
        
        # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
        self._initialize_session_state()
        
        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        cleanup_old_files()
        
        # AI ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        self.summarizer.initialize_summarizers()
    
    def _initialize_session_state(self):
        """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
        # í™”ì ë¼ë²¨ ì €ì¥
        if 'speaker_labels' not in st.session_state:
            st.session_state.speaker_labels = {}
        
        # ì¶”ì¶œ íˆìŠ¤í† ë¦¬
        if 'export_history' not in st.session_state:
            st.session_state.export_history = []
        
        # êµìœ¡ ì„¤ì •
        if 'education_settings' not in st.session_state:
            st.session_state.education_settings = {
                'lecture_type': 'general',  # general, seminar, lab, tutorial
                'summary_depth': 'medium',  # short, medium, detailed
                'include_qa': True,
                'auto_chapters': True
            }
    
    def run(self):
        """ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰"""
        self._display_header()
        self._display_sidebar()
        
        # ë©”ì¸ íƒ­ - ë…¼ë¦¬ì  ìˆœì„œë¡œ ì¬ë°°ì¹˜
        tabs = st.tabs([
            "ğŸ“¤ íŒŒì¼ ì—…ë¡œë“œ",
            "ğŸ“º YouTube ë‹¤ìš´ë¡œë“œ", 
            "ğŸ‘¥ í™”ì ë¶„ì„",
            "ğŸ¯ ìŠ¤ë§ˆíŠ¸ í¸ì§‘",
            "ğŸ“ êµìœ¡ ìš”ì•½"
        ])
        
        with tabs[0]:
            self._handle_file_upload()
        
        with tabs[1]:
            self._handle_youtube_download()
        
        with tabs[2]:
            self._display_speaker_analysis_enhanced()  # í™”ì ë¶„ì„ ë¨¼ì €
        
        with tabs[3]:
            self._display_smart_editing()  # ê·¸ ë‹¤ìŒ ìŠ¤ë§ˆíŠ¸ í¸ì§‘
        
        with tabs[4]:
            self._display_education_summary()  # ë§ˆì§€ë§‰ì— ìš”ì•½
    
    def _display_header(self):
        """í—¤ë” í‘œì‹œ"""
        col1, col2 = st.columns([3, 1])
        with col1:
            st.title("ğŸ¬ CutStudio Enhanced")
            st.markdown("**êµìœ¡ íŠ¹í™”** AI ë™ì˜ìƒ í¸ì§‘ê¸° | v4.0")
        with col2:
            if st.button("ğŸ“š ì‚¬ìš© ê°€ì´ë“œ"):
                self._show_user_guide()
    
    def _display_sidebar(self):
        """ì‚¬ì´ë“œë°” í‘œì‹œ"""
        with st.sidebar:
            st.header("âš™ï¸ ì„¤ì •")
            
            # êµìœ¡ ì„¤ì •
            st.subheader("ğŸ“ êµìœ¡ ì„¤ì •")
            
            lecture_type = st.selectbox(
                "ê°•ì˜ ìœ í˜•",
                ["general", "seminar", "lab", "tutorial"],
                format_func=lambda x: {
                    "general": "ì¼ë°˜ ê°•ì˜",
                    "seminar": "ì„¸ë¯¸ë‚˜/í† ë¡ ",
                    "lab": "ì‹¤ìŠµ/ì‹¤í—˜",
                    "tutorial": "íŠœí† ë¦¬ì–¼"
                }[x]
            )
            st.session_state.education_settings['lecture_type'] = lecture_type
            
            summary_depth = st.select_slider(
                "ìš”ì•½ ìƒì„¸ë„",
                options=["short", "medium", "detailed"],
                value="medium",
                format_func=lambda x: {
                    "short": "ê°„ë‹¨íˆ",
                    "medium": "ë³´í†µ",
                    "detailed": "ìì„¸íˆ"
                }[x]
            )
            st.session_state.education_settings['summary_depth'] = summary_depth
            
            st.session_state.education_settings['include_qa'] = st.checkbox(
                "Q&A ì„¸ì…˜ í¬í•¨", 
                value=True
            )
            
            st.session_state.education_settings['auto_chapters'] = st.checkbox(
                "ìë™ ì±•í„° ìƒì„±", 
                value=True
            )
            
            # AI ìš”ì•½ ì„¤ì •
            st.markdown("---")
            st.subheader("ğŸ¤– AI ì„¤ì •")
            self._display_ai_settings()
            
            # ë‚´ë³´ë‚´ê¸° íˆìŠ¤í† ë¦¬
            st.markdown("---")
            st.subheader("ğŸ“œ ìµœê·¼ ì‘ì—…")
            self._display_export_history()
    
    def _display_smart_editing(self):
        """ìŠ¤ë§ˆíŠ¸ í¸ì§‘ - ì›í´ë¦­ ì¶”ì¶œ ê¸°ëŠ¥"""
        st.header("ğŸ¯ ìŠ¤ë§ˆíŠ¸ í¸ì§‘")
        
        if not self.state.video_path:
            # ë¹„ë””ì˜¤ê°€ ì—†ìœ¼ë©´ ì—…ë¡œë“œ ë˜ëŠ” YouTube ë‹¤ìš´ë¡œë“œì—ì„œ ì„ íƒí•  ìˆ˜ ìˆë„ë¡ ì•ˆë‚´
            st.info("í¸ì§‘í•  ë¹„ë””ì˜¤ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
            
            # YouTube ë‹¤ìš´ë¡œë“œ ê¸°ë¡ì´ ìˆìœ¼ë©´ ì„ íƒ ì˜µì…˜ ì œê³µ
            if 'youtube_downloads' in st.session_state and st.session_state.youtube_downloads:
                st.markdown("### ğŸ“º YouTube ë‹¤ìš´ë¡œë“œ íŒŒì¼ì—ì„œ ì„ íƒ")
                
                # ìµœê·¼ ë‹¤ìš´ë¡œë“œí•œ íŒŒì¼ë“¤ í‘œì‹œ
                recent_downloads = st.session_state.youtube_downloads[-5:]  # ìµœê·¼ 5ê°œ
                
                for i, download in enumerate(recent_downloads):
                    col1, col2, col3 = st.columns([3, 1, 1])
                    
                    with col1:
                        st.write(f"ğŸ¬ **{download['title'][:50]}...**")
                        st.caption(f"í¬ê¸°: {download['size_mb']:.1f} MB | í’ˆì§ˆ: {download['quality']}")
                    
                    with col2:
                        if Path(download['path']).exists():
                            st.success("âœ… ì‚¬ìš© ê°€ëŠ¥")
                        else:
                            st.error("âŒ íŒŒì¼ ì—†ìŒ")
                    
                    with col3:
                        if Path(download['path']).exists():
                            if st.button("ğŸ“ í¸ì§‘í•˜ê¸°", key=f"edit_smart_{i}"):
                                self._load_downloaded_video(download['path'])
                                st.rerun()
                
                st.markdown("---")
            
            # íŒŒì¼ ì—…ë¡œë“œ ë˜ëŠ” YouTube ë‹¤ìš´ë¡œë“œ ì•ˆë‚´
            st.markdown("### ğŸ’¡ ë¹„ë””ì˜¤ë¥¼ í¸ì§‘í•˜ë ¤ë©´:")
            col1, col2 = st.columns(2)
            with col1:
                st.info("ğŸ“¤ **íŒŒì¼ ì—…ë¡œë“œ íƒ­**ì—ì„œ ë¹„ë””ì˜¤/ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”")
            with col2:
                st.info("ğŸ“º **YouTube ë‹¤ìš´ë¡œë“œ íƒ­**ì—ì„œ ì˜¨ë¼ì¸ ì˜ìƒì„ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”")
            
            return
        
        if not self.state.speaker_segments:
            st.warning("í™”ì ë¶„ì„ì„ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
            if st.button("í™”ì ë¶„ì„ ì‹¤í–‰í•˜ê¸°"):
                st.switch_page("pages/speaker_analysis.py")
            return
        
        # ì›í´ë¦­ ì¶”ì¶œ ì„¹ì…˜
        st.subheader("âœ¨ ì›í´ë¦­ ì¶”ì¶œ")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            if st.button("ğŸ‘¨â€ğŸ« êµìˆ˜ ê°•ì˜ë§Œ", use_container_width=True):
                self._extract_professor_only()
        
        with col2:
            if st.button("ğŸ™‹ í•™ìƒ ì§ˆë¬¸ë§Œ", use_container_width=True):
                self._extract_student_questions()
        
        with col3:
            if st.button("ğŸ’¬ Q&A ì„¸ì…˜", use_container_width=True):
                self._extract_qa_sessions()
        
        with col4:
            if st.button("ğŸ“š ì±•í„°ë³„ ë¶„ë¦¬", use_container_width=True):
                self._extract_by_chapters()
        
        # ê³ ê¸‰ ì¶”ì¶œ ì˜µì…˜
        with st.expander("ğŸ”§ ê³ ê¸‰ ì¶”ì¶œ ì˜µì…˜"):
            self._display_advanced_extraction()
        
        # ì¶”ì¶œ ê²°ê³¼ í‘œì‹œ
        if 'last_extraction' in st.session_state:
            st.markdown("---")
            self._display_extraction_results()
    
    def _display_speaker_analysis_enhanced(self):
        """ê°œì„ ëœ í™”ì ë¶„ì„ - ë¼ë²¨ë§ ê¸°ëŠ¥ í¬í•¨"""
        st.header("ğŸ‘¥ í™”ì ë¶„ì„ Pro")
        
        if not self.state.video_path:
            st.info("ë¨¼ì € ë¹„ë””ì˜¤ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
            return
        
        # í™”ì ê°ì§€ ì„¤ì •
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("ğŸ¯ í™”ì ê°ì§€")
            
            # ê°ì§€ ëª¨ë“œ ì„ íƒ - ê· í˜•ì¡íŒ ëª¨ë“œë¥¼ ê¸°ë³¸ê°’ìœ¼ë¡œ
            available_modes = self.speaker_detector.get_available_modes()
            mode_list = list(available_modes.keys())
            default_index = mode_list.index('balanced') if 'balanced' in mode_list else 0
            
            detection_mode = st.selectbox(
                "ê°ì§€ ëª¨ë“œ",
                mode_list,
                index=default_index,
                format_func=lambda x: available_modes[x]['name']
            )
            
            st.caption(available_modes[detection_mode]['description'])
            
            num_speakers = st.number_input(
                "ì˜ˆìƒ í™”ì ìˆ˜ (0=ìë™)",
                min_value=0,
                max_value=10,
                value=2,
                help="ì¼ë°˜ì ìœ¼ë¡œ êµìˆ˜ 1ëª… + í•™ìƒ ì—¬ëŸ¬ëª…"
            )
        
        with col2:
            st.subheader("ğŸ·ï¸ í™”ì ë¼ë²¨ë§")
            
            if self.state.speaker_segments:
                self._display_speaker_labeling()
            else:
                st.info("í™”ì ê°ì§€ í›„ ë¼ë²¨ì„ ì§€ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        # í™”ì ê°ì§€ ì‹¤í–‰
        if st.button("ğŸš€ í™”ì ê°ì§€ ì‹œì‘", type="primary", use_container_width=True):
            self._run_speaker_detection_enhanced(
                detection_mode,
                num_speakers if num_speakers > 0 else None
            )
        
        # ê°ì§€ ê²°ê³¼ í‘œì‹œ
        if self.state.speaker_segments:
            st.markdown("---")
            
            # í™”ìë³„ í†µê³„
            st.subheader("ğŸ“Š í™”ìë³„ í†µê³„")
            self._display_speaker_statistics()
            
            # íƒ€ì„ë¼ì¸
            st.subheader("ğŸ“ íƒ€ì„ë¼ì¸")
            if self.state.recognized_segments:
                display_timeline(
                    self.state.recognized_segments,
                    self.state.video_path,
                    speaker_labels=st.session_state.speaker_labels
                )
            else:
                if st.button("ğŸ™ï¸ ìŒì„± ì¸ì‹ ì‹œì‘"):
                    self._run_speech_recognition("base")
    
    def _display_education_summary(self):
        """êµìœ¡ íŠ¹í™” ìš”ì•½"""
        st.header("ğŸ“ êµìœ¡ íŠ¹í™” ìš”ì•½")
        
        if not self.state.recognized_segments:
            st.info("ë¨¼ì € í™”ì ë¶„ì„ê³¼ ìŒì„± ì¸ì‹ì„ ì™„ë£Œí•´ì£¼ì„¸ìš”.")
            return
        
        # ìš”ì•½ ì˜µì…˜
        col1, col2, col3 = st.columns(3)
        
        with col1:
            summary_type = st.selectbox(
                "ìš”ì•½ ìœ í˜•",
                ["full", "concepts", "qa", "exam"],
                format_func=lambda x: {
                    "full": "ì „ì²´ ìš”ì•½",
                    "concepts": "í•µì‹¬ ê°œë…ë§Œ",
                    "qa": "Q&A ì •ë¦¬",
                    "exam": "ì‹œí—˜ ëŒ€ë¹„"
                }[x]
            )
        
        with col2:
            summary_length = st.selectbox(
                "ìš”ì•½ ê¸¸ì´",
                ["1min", "5min", "15min"],
                format_func=lambda x: {
                    "1min": "1ë¶„ ìš”ì•½",
                    "5min": "5ë¶„ ìš”ì•½",
                    "15min": "15ë¶„ ìš”ì•½"
                }[x]
            )
        
        with col3:
            output_format = st.selectbox(
                "ì¶œë ¥ í˜•ì‹",
                ["markdown", "pdf", "docx"],
                format_func=lambda x: {
                    "markdown": "ë§ˆí¬ë‹¤ìš´",
                    "pdf": "PDF ë¬¸ì„œ",
                    "docx": "Word ë¬¸ì„œ"
                }[x]
            )
        
        # ìš”ì•½ ìƒì„±
        if st.button("ğŸ“ ìš”ì•½ ìƒì„±", type="primary", use_container_width=True):
            self._generate_education_summary(summary_type, summary_length)
        
        # ìš”ì•½ ê²°ê³¼ í‘œì‹œ
        if 'education_summary' in st.session_state:
            st.markdown("---")
            self._display_education_summary_results()
    
    # === í•µì‹¬ ê¸°ëŠ¥ êµ¬í˜„ ë©”ì„œë“œë“¤ ===
    
    def _extract_professor_only(self):
        """êµìˆ˜ ê°•ì˜ë§Œ ì¶”ì¶œ"""
        with st.spinner("êµìˆ˜ë‹˜ ê°•ì˜ êµ¬ê°„ì„ ì¶”ì¶œí•˜ëŠ” ì¤‘..."):
            # êµìˆ˜ë¡œ ë¼ë²¨ë§ëœ í™”ì ì°¾ê¸°
            professor_speakers = []
            for speaker, label in st.session_state.speaker_labels.items():
                if "êµìˆ˜" in label or "professor" in label.lower():
                    professor_speakers.append(speaker)
            
            if not professor_speakers and self.state.speaker_segments:
                # ë¼ë²¨ì´ ì—†ìœ¼ë©´ ê°€ì¥ ë§ì´ ë§í•œ í™”ìë¥¼ êµìˆ˜ë¡œ ì¶”ì •
                speaker_durations = {}
                for segment in self.state.speaker_segments:
                    speaker = segment['speaker']
                    duration = segment['end'] - segment['start']
                    speaker_durations[speaker] = speaker_durations.get(speaker, 0) + duration
                
                professor_speakers = [max(speaker_durations, key=speaker_durations.get)]
            
            # êµìˆ˜ ì„¸ê·¸ë¨¼íŠ¸ë§Œ ì¶”ì¶œ
            professor_segments = [
                seg for seg in self.state.speaker_segments 
                if seg['speaker'] in professor_speakers
            ]
            
            if professor_segments:
                # ë¹„ë””ì˜¤ í¸ì§‘ ë° ë‚´ë³´ë‚´ê¸°
                output_path = self._merge_and_export_segments(
                    professor_segments, 
                    "professor_only"
                )
                
                st.session_state.last_extraction = {
                    'type': 'professor_only',
                    'path': output_path,
                    'segments': len(professor_segments),
                    'duration': sum(s['end'] - s['start'] for s in professor_segments)
                }
                
                st.success(f"âœ… êµìˆ˜ ê°•ì˜ ì¶”ì¶œ ì™„ë£Œ! ({len(professor_segments)}ê°œ êµ¬ê°„)")
            else:
                st.error("êµìˆ˜ í™”ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í™”ì ë¼ë²¨ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    
    def _extract_student_questions(self):
        """í•™ìƒ ì§ˆë¬¸ë§Œ ì¶”ì¶œ"""
        with st.spinner("í•™ìƒ ì§ˆë¬¸ êµ¬ê°„ì„ ì¶”ì¶œí•˜ëŠ” ì¤‘..."):
            # í•™ìƒìœ¼ë¡œ ë¼ë²¨ë§ëœ í™”ì ì°¾ê¸°
            student_speakers = []
            for speaker, label in st.session_state.speaker_labels.items():
                if "í•™ìƒ" in label or "student" in label.lower() or speaker != "SPEAKER_0":
                    student_speakers.append(speaker)
            
            # í•™ìƒ ì„¸ê·¸ë¨¼íŠ¸ ì¶”ì¶œ
            student_segments = [
                seg for seg in self.state.speaker_segments 
                if seg['speaker'] in student_speakers
            ]
            
            if student_segments:
                output_path = self._merge_and_export_segments(
                    student_segments, 
                    "student_questions"
                )
                
                st.session_state.last_extraction = {
                    'type': 'student_questions',
                    'path': output_path,
                    'segments': len(student_segments),
                    'duration': sum(s['end'] - s['start'] for s in student_segments)
                }
                
                st.success(f"âœ… í•™ìƒ ì§ˆë¬¸ ì¶”ì¶œ ì™„ë£Œ! ({len(student_segments)}ê°œ êµ¬ê°„)")
            else:
                st.warning("í•™ìƒ ë°œí™”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    def _extract_qa_sessions(self):
        """Q&A ì„¸ì…˜ ì¶”ì¶œ - êµìˆ˜-í•™ìƒ ìƒí˜¸ì‘ìš©"""
        with st.spinner("Q&A ì„¸ì…˜ì„ ì¶”ì¶œí•˜ëŠ” ì¤‘..."):
            qa_segments = []
            segments = self.state.speaker_segments
            
            for i in range(len(segments) - 1):
                current = segments[i]
                next_seg = segments[i + 1]
                
                # í™”ìê°€ ë°”ë€ŒëŠ” êµ¬ê°„ ì°¾ê¸°
                if current['speaker'] != next_seg['speaker']:
                    # ì „í›„ ì»¨í…ìŠ¤íŠ¸ í¬í•¨ (5ì´ˆ)
                    start_time = max(0, current['start'] - 5)
                    end_time = min(next_seg['end'] + 5, self.state.video_editor.duration)
                    
                    qa_segments.append({
                        'start': start_time,
                        'end': end_time,
                        'speakers': [current['speaker'], next_seg['speaker']]
                    })
            
            if qa_segments:
                # ì¤‘ë³µ ì œê±° ë° ë³‘í•©
                merged_segments = self._merge_overlapping_segments(qa_segments)
                output_path = self._merge_and_export_segments(
                    merged_segments, 
                    "qa_sessions"
                )
                
                st.session_state.last_extraction = {
                    'type': 'qa_sessions',
                    'path': output_path,
                    'segments': len(merged_segments),
                    'duration': sum(s['end'] - s['start'] for s in merged_segments)
                }
                
                st.success(f"âœ… Q&A ì„¸ì…˜ ì¶”ì¶œ ì™„ë£Œ! ({len(merged_segments)}ê°œ ì„¸ì…˜)")
            else:
                st.warning("Q&A ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    def _extract_by_chapters(self):
        """ì±•í„°ë³„ ë¶„ë¦¬"""
        with st.spinner("ì±•í„°ë¥¼ ë¶„ì„í•˜ëŠ” ì¤‘..."):
            # ê°„ë‹¨í•œ ì±•í„° ê°ì§€ (10ë¶„ ë‹¨ìœ„ ë˜ëŠ” ì£¼ì œ ë³€ê²½)
            video_duration = self.state.video_editor.duration
            chapter_duration = 600  # 10ë¶„
            
            chapters = []
            for i in range(0, int(video_duration), chapter_duration):
                start = i
                end = min(i + chapter_duration, video_duration)
                chapters.append({
                    'start': start,
                    'end': end,
                    'title': f"Chapter {len(chapters) + 1}"
                })
            
            # ê° ì±•í„°ë³„ë¡œ ë‚´ë³´ë‚´ê¸°
            output_paths = []
            for i, chapter in enumerate(chapters):
                output_path = Path(self.config.PROCESSED_DIR) / f"chapter_{i+1}.mp4"
                # ì‹¤ì œ ë¹„ë””ì˜¤ ìë¥´ê¸° êµ¬í˜„...
                output_paths.append(str(output_path))
            
            st.session_state.last_extraction = {
                'type': 'chapters',
                'paths': output_paths,
                'count': len(chapters)
            }
            
            st.success(f"âœ… {len(chapters)}ê°œ ì±•í„°ë¡œ ë¶„ë¦¬ ì™„ë£Œ!")
    
    def _display_speaker_labeling(self):
        """í™”ì ë¼ë²¨ë§ UI"""
        st.write("ê° í™”ìì˜ ì´ë¦„ì´ë‚˜ ì—­í• ì„ ì§€ì •í•˜ì„¸ìš”:")
        
        # í™”ìë³„ ìƒ˜í”Œ ì¬ìƒ ë° ë¼ë²¨ ì…ë ¥
        for speaker in set(seg['speaker'] for seg in self.state.speaker_segments):
            col1, col2, col3 = st.columns([1, 2, 2])
            
            with col1:
                st.write(f"**{speaker}**")
            
            with col2:
                # í•´ë‹¹ í™”ìì˜ ì²« ë²ˆì§¸ ì„¸ê·¸ë¨¼íŠ¸ ì°¾ê¸°
                first_segment = next(
                    seg for seg in self.state.speaker_segments 
                    if seg['speaker'] == speaker
                )
                
                if st.button(f"ğŸ”Š ìƒ˜í”Œ ë“£ê¸°", key=f"play_{speaker}"):
                    # ì˜¤ë””ì˜¤ ì¬ìƒ ë¡œì§
                    st.info(f"{format_time(first_segment['start'])} - {format_time(first_segment['end'])}")
            
            with col3:
                # ê¸°ì¡´ ë¼ë²¨ ë˜ëŠ” ê¸°ë³¸ê°’
                default_label = st.session_state.speaker_labels.get(
                    speaker, 
                    "êµìˆ˜" if speaker == "SPEAKER_0" else f"í•™ìƒ{speaker[-1]}"
                )
                
                label = st.text_input(
                    "ì´ë¦„/ì—­í• ",
                    value=default_label,
                    key=f"label_{speaker}"
                )
                
                st.session_state.speaker_labels[speaker] = label
        
        # ë¼ë²¨ ì €ì¥
        if st.button("ğŸ’¾ ë¼ë²¨ ì €ì¥"):
            self._save_speaker_labels()
            st.success("ë¼ë²¨ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
    
    def _generate_education_summary(self, summary_type: str, length: str):
        """êµìœ¡ íŠ¹í™” ìš”ì•½ ìƒì„±"""
        with st.spinner("AIê°€ ê°•ì˜ë¥¼ ë¶„ì„í•˜ëŠ” ì¤‘..."):
            # ì „ì²´ í…ìŠ¤íŠ¸ ì¤€ë¹„
            full_transcript = self._prepare_transcript_for_summary()
            
            # êµìœ¡ íŠ¹í™” í”„ë¡¬í”„íŠ¸
            prompts = {
                "full": f"""
                ë‹¤ìŒ ê°•ì˜ ë‚´ìš©ì„ {length} ë¶„ëŸ‰ìœ¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”.
                í¬í•¨í•  ë‚´ìš©:
                1. í•™ìŠµ ëª©í‘œ
                2. í•µì‹¬ ê°œë… (ì •ì˜ í¬í•¨)
                3. ìƒì„¸ ì„¤ëª…
                4. ì˜ˆì‹œ/ì‚¬ë¡€
                5. Q&A ìš”ì•½
                6. ë‹¤ìŒ ìˆ˜ì—… ì¤€ë¹„ì‚¬í•­
                
                ê°•ì˜ ë‚´ìš©:
                {full_transcript}
                """,
                
                "concepts": f"""
                ë‹¤ìŒ ê°•ì˜ì—ì„œ í•µì‹¬ ê°œë…ë§Œ ì¶”ì¶œí•´ì£¼ì„¸ìš”.
                - ì •ì˜ê°€ í¬í•¨ëœ ê°œë…
                - 2ë²ˆ ì´ìƒ ë°˜ë³µëœ ì¤‘ìš” ë‚´ìš©
                - ì „ë¬¸ ìš©ì–´ì™€ ì„¤ëª…
                
                ê°•ì˜ ë‚´ìš©:
                {full_transcript}
                """,
                
                "qa": f"""
                ë‹¤ìŒ ê°•ì˜ì—ì„œ Q&A ì„¸ì…˜ë§Œ ì •ë¦¬í•´ì£¼ì„¸ìš”.
                - í•™ìƒ ì§ˆë¬¸
                - êµìˆ˜ ë‹µë³€
                - ì¶”ê°€ ì„¤ëª…ì´ í•„ìš”í•œ ë¶€ë¶„
                
                ê°•ì˜ ë‚´ìš©:
                {full_transcript}
                """,
                
                "exam": f"""
                ë‹¤ìŒ ê°•ì˜ì—ì„œ ì‹œí—˜ì— ë‚˜ì˜¬ ë§Œí•œ ë‚´ìš©ì„ ì •ë¦¬í•´ì£¼ì„¸ìš”.
                - "ì¤‘ìš”", "ì‹œí—˜", "ê¼­ ê¸°ì–µ" ì–¸ê¸‰ ë¶€ë¶„
                - í•µì‹¬ ì •ì˜ì™€ ê³µì‹
                - ì˜ˆìƒ ë¬¸ì œ
                
                ê°•ì˜ ë‚´ìš©:
                {full_transcript}
                """
            }
            
            # AI ìš”ì•½ ìƒì„±
            summary = self.summarizer.summarize_text(
                prompts[summary_type],
                max_length={"1min": 200, "5min": 1000, "15min": 3000}[length]
            )
            
            st.session_state.education_summary = {
                'type': summary_type,
                'length': length,
                'content': summary,
                'timestamp': datetime.now()
            }
    
    def _merge_and_export_segments(self, segments: List[Dict], output_name: str) -> str:
        """ì„¸ê·¸ë¨¼íŠ¸ ë³‘í•© ë° ë‚´ë³´ë‚´ê¸°"""
        output_path = Path(self.config.PROCESSED_DIR) / f"{output_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.mp4"
        
        # VideoEditorë¥¼ ì‚¬ìš©í•˜ì—¬ ì„¸ê·¸ë¨¼íŠ¸ ë³‘í•©
        if hasattr(self.state.video_editor, 'merge_segments'):
            self.state.video_editor.merge_segments(segments, str(output_path))
        else:
            # í´ë°±: ì²« ë²ˆì§¸ ì„¸ê·¸ë¨¼íŠ¸ë§Œ ì¶”ì¶œ
            if segments:
                self.state.video_editor.cut_video(
                    segments[0]['start'], 
                    segments[-1]['end'], 
                    str(output_path)
                )
        
        # ë‚´ë³´ë‚´ê¸° íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
        st.session_state.export_history.append({
            'name': output_name,
            'path': str(output_path),
            'timestamp': datetime.now(),
            'segments': len(segments)
        })
        
        return str(output_path)
    
    def _display_extraction_results(self):
        """ì¶”ì¶œ ê²°ê³¼ í‘œì‹œ"""
        extraction = st.session_state.last_extraction
        
        st.subheader("ğŸ“¤ ì¶”ì¶œ ê²°ê³¼")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("ì¶”ì¶œ ìœ í˜•", extraction['type'].replace('_', ' ').title())
        
        with col2:
            if 'segments' in extraction:
                st.metric("ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜", extraction['segments'])
            elif 'count' in extraction:
                st.metric("íŒŒì¼ ìˆ˜", extraction['count'])
        
        with col3:
            if 'duration' in extraction:
                st.metric("ì´ ê¸¸ì´", format_time(extraction['duration']))
        
        # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
        if 'path' in extraction and Path(extraction['path']).exists():
            with open(extraction['path'], 'rb') as f:
                st.download_button(
                    "â¬‡ï¸ ë‹¤ìš´ë¡œë“œ",
                    data=f,
                    file_name=Path(extraction['path']).name,
                    mime="video/mp4",
                    use_container_width=True
                )
        elif 'paths' in extraction:
            st.info(f"{len(extraction['paths'])}ê°œ íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    def _display_export_history(self):
        """ë‚´ë³´ë‚´ê¸° íˆìŠ¤í† ë¦¬ í‘œì‹œ"""
        if st.session_state.export_history:
            for export in st.session_state.export_history[-5:]:  # ìµœê·¼ 5ê°œ
                with st.expander(f"{export['name']} - {export['timestamp'].strftime('%H:%M')}"):
                    st.write(f"ì„¸ê·¸ë¨¼íŠ¸: {export['segments']}ê°œ")
                    if Path(export['path']).exists():
                        st.write("âœ… íŒŒì¼ ì‚¬ìš© ê°€ëŠ¥")
                    else:
                        st.write("âŒ íŒŒì¼ ì—†ìŒ")
        else:
            st.info("ì•„ì§ ë‚´ë³´ë‚¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    def _merge_overlapping_segments(self, segments):
        """ê²¹ì¹˜ëŠ” ì„¸ê·¸ë¨¼íŠ¸ ë³‘í•© - VideoEditorì˜ ë©”ì„œë“œ í™œìš©"""
        if hasattr(self.state.video_editor, 'merge_overlapping_segments'):
            return self.state.video_editor.merge_overlapping_segments(segments, padding=2)
        return segments
    
    def _save_speaker_labels(self):
        """í™”ì ë¼ë²¨ ì €ì¥"""
        if self.state.video_path:
            # ë¼ë²¨ ì •ë³´ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥
            labels_file = Path(self.state.video_path).with_suffix('.labels.json')
            with open(labels_file, 'w', encoding='utf-8') as f:
                json.dump({
                    'labels': st.session_state.speaker_labels,
                    'video_path': self.state.video_path,
                    'timestamp': datetime.now().isoformat()
                }, f, ensure_ascii=False, indent=2)
    
    def _prepare_transcript_for_summary(self) -> str:
        """ìš”ì•½ì„ ìœ„í•œ ì „ì²´ íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ ì¤€ë¹„"""
        if not self.state.recognized_segments:
            return ""
        
        transcript_lines = []
        for segment in self.state.recognized_segments:
            speaker = segment.get('speaker', 'Unknown')
            # ë¼ë²¨ì´ ìˆìœ¼ë©´ ì‚¬ìš©
            if speaker in st.session_state.speaker_labels:
                speaker = st.session_state.speaker_labels[speaker]
            
            text = segment.get('text', '').strip()
            if text:
                transcript_lines.append(f"{speaker}: {text}")
        
        return "\n".join(transcript_lines)
    
    def _display_speaker_statistics(self):
        """í™”ìë³„ í†µê³„ í‘œì‹œ"""
        if not self.state.speaker_segments:
            return
        
        # í™”ìë³„ í†µê³„ ê³„ì‚°
        speaker_stats = {}
        total_duration = 0
        
        for segment in self.state.speaker_segments:
            speaker = segment['speaker']
            duration = segment['end'] - segment['start']
            
            if speaker not in speaker_stats:
                speaker_stats[speaker] = {
                    'duration': 0,
                    'count': 0,
                    'first': segment['start'],
                    'last': segment['end']
                }
            
            speaker_stats[speaker]['duration'] += duration
            speaker_stats[speaker]['count'] += 1
            speaker_stats[speaker]['last'] = max(speaker_stats[speaker]['last'], segment['end'])
            total_duration += duration
        
        # í†µê³„ í‘œì‹œ
        cols = st.columns(len(speaker_stats))
        for i, (speaker, stats) in enumerate(speaker_stats.items()):
            with cols[i]:
                # ë¼ë²¨ ì‚¬ìš©
                label = st.session_state.speaker_labels.get(speaker, speaker)
                st.metric(
                    label,
                    f"{format_time(stats['duration'])}",
                    f"{stats['count']}ê°œ êµ¬ê°„"
                )
                
                # ì°¸ì—¬ìœ¨
                participation = (stats['duration'] / total_duration * 100) if total_duration > 0 else 0
                st.progress(participation / 100)
                st.caption(f"{participation:.1f}% ì°¸ì—¬")
    
    def _display_ai_settings(self):
        """AI ì„¤ì • í‘œì‹œ"""
        # ìš”ì•½ê¸° ìƒíƒœ í‘œì‹œ
        col1, col2 = st.columns(2)
        with col1:
            if self.summarizer.gemini_summarizer:
                st.success("âœ… Gemini")
            else:
                st.error("âŒ Gemini")
        
        with col2:
            if self.summarizer.claude_summarizer:
                st.success("âœ… Claude")
            else:
                st.info("â¸ï¸ Claude")
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ìš”ì•½ê¸° ì„ íƒ
        available_summarizers = []
        if self.summarizer.gemini_summarizer:
            available_summarizers.append("Gemini")
        if self.summarizer.claude_summarizer:
            available_summarizers.append("Claude")
        
        if available_summarizers:
            selected = st.selectbox(
                "ìš”ì•½ AI ì„ íƒ",
                available_summarizers,
                key="summarizer_select"
            )
            self.summarizer.active_summarizer = selected.lower()
    
    def _display_advanced_extraction(self):
        """ê³ ê¸‰ ì¶”ì¶œ ì˜µì…˜"""
        col1, col2 = st.columns(2)
        
        with col1:
            min_segment_duration = st.slider(
                "ìµœì†Œ ì„¸ê·¸ë¨¼íŠ¸ ê¸¸ì´ (ì´ˆ)",
                min_value=1,
                max_value=30,
                value=5,
                help="ì´ë³´ë‹¤ ì§§ì€ ë°œí™”ëŠ” ì œì™¸ë©ë‹ˆë‹¤"
            )
            
            merge_gap = st.slider(
                "ì„¸ê·¸ë¨¼íŠ¸ ë³‘í•© ê°„ê²© (ì´ˆ)",
                min_value=0,
                max_value=10,
                value=2,
                help="ì´ ê°„ê²© ì´ë‚´ì˜ ê°™ì€ í™”ì ë°œí™”ëŠ” í•˜ë‚˜ë¡œ ë³‘í•©"
            )
        
        with col2:
            include_context = st.checkbox(
                "ì „í›„ ì»¨í…ìŠ¤íŠ¸ í¬í•¨",
                value=True,
                help="ê° ì„¸ê·¸ë¨¼íŠ¸ ì „í›„ 5ì´ˆë¥¼ ì¶”ê°€ë¡œ í¬í•¨"
            )
            
            if include_context:
                context_seconds = st.number_input(
                    "ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ (ì´ˆ)",
                    min_value=1,
                    max_value=30,
                    value=5
                )
        
        # ê³ ê¸‰ ì¶”ì¶œ ì‹¤í–‰
        if st.button("ğŸš€ ê³ ê¸‰ ì¶”ì¶œ ì‹¤í–‰", use_container_width=True):
            self._run_advanced_extraction(
                min_segment_duration,
                merge_gap,
                include_context,
                context_seconds if include_context else 0
            )
    
    def _run_advanced_extraction(self, min_duration, merge_gap, include_context, context_seconds):
        """ê³ ê¸‰ ì¶”ì¶œ ì‹¤í–‰"""
        with st.spinner("ê³ ê¸‰ ì˜µì…˜ìœ¼ë¡œ ì¶”ì¶œ ì¤‘..."):
            # í•„í„°ë§: ìµœì†Œ ê¸¸ì´ ì´ìƒì¸ ì„¸ê·¸ë¨¼íŠ¸ë§Œ
            filtered_segments = [
                seg for seg in self.state.speaker_segments
                if (seg['end'] - seg['start']) >= min_duration
            ]
            
            # ë³‘í•©: ê°™ì€ í™”ìì˜ ê°€ê¹Œìš´ ì„¸ê·¸ë¨¼íŠ¸
            merged_segments = self._merge_same_speaker_segments(filtered_segments, merge_gap)
            
            # ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
            if include_context and hasattr(self.state.video_editor, 'export_segments_with_context'):
                output_path = self.state.video_editor.export_segments_with_context(
                    merged_segments,
                    context_before=context_seconds,
                    context_after=context_seconds
                )
            else:
                output_path = self._merge_and_export_segments(merged_segments, "advanced_extraction")
            
            if output_path:
                st.success("âœ… ê³ ê¸‰ ì¶”ì¶œ ì™„ë£Œ!")
                st.session_state.last_extraction = {
                    'type': 'advanced',
                    'path': output_path,
                    'segments': len(merged_segments),
                    'duration': sum(s['end'] - s['start'] for s in merged_segments)
                }
    
    def _merge_same_speaker_segments(self, segments, max_gap):
        """ê°™ì€ í™”ìì˜ ê°€ê¹Œìš´ ì„¸ê·¸ë¨¼íŠ¸ ë³‘í•©"""
        if not segments:
            return []
        
        sorted_segments = sorted(segments, key=lambda x: x['start'])
        merged = [sorted_segments[0].copy()]
        
        for current in sorted_segments[1:]:
            last = merged[-1]
            
            # ê°™ì€ í™”ìì´ê³  ê°„ê²©ì´ max_gap ì´ë‚´ì¸ ê²½ìš° ë³‘í•©
            if (current['speaker'] == last['speaker'] and 
                current['start'] - last['end'] <= max_gap):
                last['end'] = current['end']
                # í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ í•©ì¹˜ê¸°
                if 'text' in last and 'text' in current:
                    last['text'] = last['text'] + " " + current['text']
            else:
                merged.append(current.copy())
        
        return merged
    
    def _run_speaker_detection_enhanced(self, mode, num_speakers):
        """ê°œì„ ëœ í™”ì ê°ì§€ ì‹¤í–‰"""
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        def progress_callback(current, total, message="ì²˜ë¦¬ ì¤‘..."):
            progress = current / total if total > 0 else 0
            progress_bar.progress(progress)
            status_text.text(f"{message} ({current}/{total})")
        
        try:
            # í™”ì ê°ì§€ ì‹¤í–‰
            segments = self.speaker_detector.detect_speakers(
                self.state.video_path,
                mode=mode,
                num_speakers=num_speakers,
                progress_callback=progress_callback
            )
            
            if segments:
                self.state.speaker_segments = segments
                
                # í™”ì í”„ë¡œí•„ ìƒì„±
                if self.state.video_editor:
                    self.state.segment_profiles = self.state.video_editor.generate_speaker_profile(segments)
                
                progress_bar.progress(1.0)
                status_text.text("í™”ì ê°ì§€ ì™„ë£Œ!")
                st.success(f"âœ… {len(segments)}ê°œì˜ í™”ì êµ¬ê°„ì„ ê°ì§€í–ˆìŠµë‹ˆë‹¤!")
                
                # ìë™ ë¼ë²¨ë§ ì œì•ˆ
                self._suggest_speaker_labels()
            else:
                st.error("í™”ìë¥¼ ê°ì§€í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        
        except Exception as e:
            st.error(f"í™”ì ê°ì§€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        finally:
            progress_bar.empty()
            status_text.empty()
    
    def _suggest_speaker_labels(self):
        """í™”ì ë¼ë²¨ ìë™ ì œì•ˆ"""
        if not self.state.speaker_segments:
            return
        
        # í™”ìë³„ ë°œí™” ì‹œê°„ ê³„ì‚°
        speaker_durations = {}
        for segment in self.state.speaker_segments:
            speaker = segment['speaker']
            duration = segment['end'] - segment['start']
            speaker_durations[speaker] = speaker_durations.get(speaker, 0) + duration
        
        # ê°€ì¥ ë§ì´ ë§í•œ í™”ìë¥¼ êµìˆ˜ë¡œ ì¶”ì •
        if speaker_durations:
            main_speaker = max(speaker_durations, key=speaker_durations.get)
            
            # ê¸°ë³¸ ë¼ë²¨ ì œì•ˆ
            for i, speaker in enumerate(sorted(speaker_durations.keys())):
                if speaker not in st.session_state.speaker_labels:
                    if speaker == main_speaker:
                        st.session_state.speaker_labels[speaker] = "êµìˆ˜"
                    else:
                        st.session_state.speaker_labels[speaker] = f"í•™ìƒ{i}"
    
    def _display_education_summary_results(self):
        """êµìœ¡ ìš”ì•½ ê²°ê³¼ í‘œì‹œ"""
        summary_data = st.session_state.education_summary
        
        # ìš”ì•½ ë©”íƒ€ë°ì´í„°
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("ìš”ì•½ ìœ í˜•", summary_data['type'].replace('_', ' ').title())
        with col2:
            st.metric("ìš”ì•½ ê¸¸ì´", summary_data['length'])
        with col3:
            st.metric("ìƒì„± ì‹œê°„", summary_data['timestamp'].strftime('%H:%M'))
        
        # ìš”ì•½ ë‚´ìš©
        st.markdown("### ğŸ“„ ìš”ì•½ ë‚´ìš©")
        st.markdown(summary_data['content'])
        
        # ë‹¤ìš´ë¡œë“œ ì˜µì…˜
        st.download_button(
            "ğŸ“¥ ìš”ì•½ ë‹¤ìš´ë¡œë“œ (í…ìŠ¤íŠ¸)",
            data=summary_data['content'],
            file_name=f"lecture_summary_{summary_data['type']}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
            mime="text/plain"
        )
    
    def _run_speech_recognition(self, whisper_model):
        """ìŒì„± ì¸ì‹ ì‹¤í–‰"""
        if not self.state.speaker_segments:
            st.error("ë¨¼ì € í™”ì ê°ì§€ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
            return
        
        with st.spinner(f"ìŒì„± ì¸ì‹ ì¤‘... (ëª¨ë¸: {whisper_model})"):
            try:
                recognized_segments = self.speech_processor.process_segments(
                    self.state.video_path,
                    self.state.speaker_segments,
                    whisper_model=whisper_model
                )
                
                if recognized_segments:
                    self.state.recognized_segments = recognized_segments
                    st.success(f"âœ… ìŒì„± ì¸ì‹ ì™„ë£Œ! {len(recognized_segments)}ê°œ ì„¸ê·¸ë¨¼íŠ¸")
                else:
                    st.error("ìŒì„± ì¸ì‹ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            
            except Exception as e:
                st.error(f"ìŒì„± ì¸ì‹ ì¤‘ ì˜¤ë¥˜: {str(e)}")
    
    # === ê¸°ì¡´ ë©”ì„œë“œë“¤ (app_refactored.pyì—ì„œ ê°€ì ¸ì˜´) ===
    
    def _handle_file_upload(self):
        """íŒŒì¼ ì—…ë¡œë“œ ì²˜ë¦¬"""
        st.header("ğŸ“¤ ë¯¸ë””ì–´ íŒŒì¼ ì—…ë¡œë“œ")
        
        uploaded_file = st.file_uploader(
            "ë¹„ë””ì˜¤ ë˜ëŠ” ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”",
            type=self.config.get_all_supported_formats(),
            help=f"ì§€ì› í˜•ì‹: ë¹„ë””ì˜¤({', '.join(self.config.SUPPORTED_VIDEO_FORMATS)}), ì˜¤ë””ì˜¤({', '.join(self.config.SUPPORTED_AUDIO_FORMATS)})"
        )
        
        if uploaded_file is not None:
            # íŒŒì¼ ì €ì¥
            temp_path = Path(self.config.TEMP_DIR)
            temp_path.mkdir(exist_ok=True)
            
            video_path = temp_path / uploaded_file.name
            with open(video_path, "wb") as f:
                f.write(uploaded_file.getbuffer())
            
            st.success(f"âœ… íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ: {uploaded_file.name}")
            
            # ë¯¸ë””ì–´ ì—ë””í„° ì´ˆê¸°í™”
            self.state.video_editor = VideoEditor()
            self.state.video_editor.load_video(str(video_path))
            self.state.video_path = str(video_path)
            
            # ë¯¸ë””ì–´ ì •ë³´ í‘œì‹œ
            self._display_media_info()
    
    def _handle_youtube_download(self):
        """YouTube ë‹¤ìš´ë¡œë“œ ì²˜ë¦¬"""
        st.header("ğŸ“º YouTube ë™ì˜ìƒ ë‹¤ìš´ë¡œë“œ")
        
        # YouTube URL ì…ë ¥
        youtube_url = st.text_input(
            "YouTube URLì„ ì…ë ¥í•˜ì„¸ìš”",
            placeholder="https://www.youtube.com/watch?v=...",
            help="YouTube ë™ì˜ìƒ ë˜ëŠ” ì¬ìƒëª©ë¡ URLì„ ì…ë ¥í•˜ì„¸ìš”"
        )
        
        if youtube_url:
            # URL ìœ íš¨ì„± ê°„ë‹¨ ì²´í¬
            if "youtube.com" in youtube_url or "youtu.be" in youtube_url:
                
                col1, col2 = st.columns(2)
                
                with col1:
                    download_quality = st.selectbox(
                        "ë‹¤ìš´ë¡œë“œ í’ˆì§ˆ",
                        ["highest", "720p", "480p", "360p", "audio_only"],
                        format_func=lambda x: {
                            "highest": "ìµœê³  í™”ì§ˆ",
                            "720p": "720p (HD)",
                            "480p": "480p (SD)", 
                            "360p": "360p (ì €í™”ì§ˆ)",
                            "audio_only": "ì˜¤ë””ì˜¤ë§Œ"
                        }[x]
                    )
                
                with col2:
                    download_format = st.selectbox(
                        "íŒŒì¼ í˜•ì‹",
                        ["mp4", "webm", "mp3"] if download_quality != "audio_only" else ["mp3", "m4a", "wav"],
                        format_func=lambda x: {
                            "mp4": "MP4 (ì¶”ì²œ)",
                            "webm": "WebM",
                            "mp3": "MP3 (ì˜¤ë””ì˜¤)",
                            "m4a": "M4A (ì˜¤ë””ì˜¤)",
                            "wav": "WAV (ì˜¤ë””ì˜¤)"
                        }[x]
                    )
                
                # ê³ ê¸‰ ì˜µì…˜
                with st.expander("ğŸ”§ ê³ ê¸‰ ì˜µì…˜"):
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        start_time = st.text_input(
                            "ì‹œì‘ ì‹œê°„ (ì„ íƒì‚¬í•­)",
                            placeholder="00:10:30",
                            help="í˜•ì‹: HH:MM:SS ë˜ëŠ” MM:SS"
                        )
                    
                    with col2:
                        end_time = st.text_input(
                            "ì¢…ë£Œ ì‹œê°„ (ì„ íƒì‚¬í•­)",
                            placeholder="01:20:15",
                            help="í˜•ì‹: HH:MM:SS ë˜ëŠ” MM:SS"
                        )
                    
                    subtitle_download = st.checkbox(
                        "ìë§‰ ë‹¤ìš´ë¡œë“œ",
                        value=False,
                        help="ì‚¬ìš© ê°€ëŠ¥í•œ ìë§‰ì„ í•¨ê»˜ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤"
                    )
                
                # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                if st.button("ğŸ“¥ ë‹¤ìš´ë¡œë“œ ì‹œì‘", type="primary", use_container_width=True):
                    self._download_youtube_video(
                        youtube_url,
                        download_quality,
                        download_format,
                        start_time,
                        end_time,
                        subtitle_download
                    )
            
            else:
                st.error("âŒ ìœ íš¨í•œ YouTube URLì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        
        # ë‹¤ìš´ë¡œë“œ íˆìŠ¤í† ë¦¬
        if 'youtube_downloads' in st.session_state and st.session_state.youtube_downloads:
            st.markdown("---")
            st.subheader("ğŸ“œ ë‹¤ìš´ë¡œë“œ ê¸°ë¡")
            
            for download in st.session_state.youtube_downloads[-3:]:  # ìµœê·¼ 3ê°œ
                with st.expander(f"ğŸ¬ {download['title'][:50]}..."):
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        st.metric("í’ˆì§ˆ", download['quality'])
                    with col2:
                        st.metric("í¬ê¸°", f"{download['size_mb']:.1f} MB")
                    with col3:
                        st.metric("ì‹œê°„", download['duration'])
                    
                    if Path(download['path']).exists():
                        # ì´ íŒŒì¼ì„ í¸ì§‘ì— ì‚¬ìš©í•˜ê¸°
                        if st.button("âœ‚ï¸ ì´ íŒŒì¼ë¡œ í¸ì§‘í•˜ê¸°", key=f"youtube_edit_{i}"):
                            self._load_downloaded_video(download['path'])
                            st.success("âœ… íŒŒì¼ì´ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤! ìŠ¤ë§ˆíŠ¸ í¸ì§‘ íƒ­ìœ¼ë¡œ ì´ë™í•˜ì„¸ìš”.")
                    else:
                        st.warning("âš ï¸ íŒŒì¼ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    def _download_youtube_video(self, url, quality, format_type, start_time, end_time, include_subtitle):
        """YouTube ë™ì˜ìƒ ë‹¤ìš´ë¡œë“œ ì‹¤í–‰"""
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        try:
            status_text.text("ğŸ“¡ ë™ì˜ìƒ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘...")
            progress_bar.progress(0.1)
            
            # ë‹¤ìš´ë¡œë“œ ì˜µì…˜ ì„¤ì •
            download_options = {
                'quality': quality,
                'format': format_type,
                'include_subtitle': include_subtitle
            }
            
            # ì‹œê°„ êµ¬ê°„ ì„¤ì •
            if start_time:
                download_options['start_time'] = start_time
            if end_time:
                download_options['end_time'] = end_time
            
            # ì§„í–‰ë¥  ì½œë°±
            def progress_callback(current, total, message="ë‹¤ìš´ë¡œë“œ ì¤‘..."):
                if total > 0:
                    progress = 0.1 + (current / total) * 0.9
                    progress_bar.progress(progress)
                    status_text.text(f"{message} ({current}/{total})")
            
            status_text.text("â¬‡ï¸ ë‹¤ìš´ë¡œë“œ ì‹œì‘...")
            progress_bar.progress(0.2)
            
            # YouTube ë‹¤ìš´ë¡œë“œ ì‹¤í–‰ (ê¸°ì¡´ ë©”ì„œë“œ ì‹œê·¸ë‹ˆì²˜ì— ë§ì¶¤)
            def youtube_progress_callback(percent, downloaded, total):
                progress = 0.2 + (percent / 100) * 0.7
                progress_bar.progress(progress)
                status_text.text(f"â¬‡ï¸ ë‹¤ìš´ë¡œë“œ ì¤‘... {percent:.1f}%")
            
            downloaded_path = self.youtube_downloader.download_video(
                url=url,
                format_id=None,  # ê¸°ë³¸ ìµœê³  í’ˆì§ˆ
                progress_callback=youtube_progress_callback
            )
            
            if downloaded_path and os.path.exists(downloaded_path):
                progress_bar.progress(1.0)
                status_text.text("âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
                
                # íŒŒì¼ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                file_size_mb = os.path.getsize(downloaded_path) / (1024 * 1024)
                filename = Path(downloaded_path).stem
                
                # ë‹¤ìš´ë¡œë“œ ê¸°ë¡ ì €ì¥
                if 'youtube_downloads' not in st.session_state:
                    st.session_state.youtube_downloads = []
                
                st.session_state.youtube_downloads.append({
                    'title': filename,
                    'path': downloaded_path,
                    'quality': quality,
                    'format': format_type,
                    'size_mb': file_size_mb,
                    'duration': 'Unknown',
                    'download_time': datetime.now(),
                    'url': url
                })
                
                st.success(f"âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {filename}")
                
                # ìë™ìœ¼ë¡œ í¸ì§‘ê¸°ì— ë¡œë“œí• ì§€ ë¬»ê¸°
                if st.button("ğŸš€ ë°”ë¡œ í¸ì§‘í•˜ê¸°"):
                    self._load_downloaded_video(downloaded_path)
                    st.rerun()
            
            else:
                st.error("âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        except Exception as e:
            st.error(f"âŒ ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        
        finally:
            progress_bar.empty()
            status_text.empty()
    
    def _load_downloaded_video(self, file_path):
        """ë‹¤ìš´ë¡œë“œëœ ë¹„ë””ì˜¤ë¥¼ í¸ì§‘ê¸°ì— ë¡œë“œ"""
        try:
            # VideoEditor ì´ˆê¸°í™”
            self.state.video_editor = VideoEditor()
            self.state.video_editor.load_video(file_path)
            self.state.video_path = file_path
            
            # ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸
            st.session_state.video_path = file_path
            
        except Exception as e:
            st.error(f"íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
    
    def _display_media_info(self):
        """ë¯¸ë””ì–´ ì •ë³´ í‘œì‹œ"""
        if self.state.video_editor:
            info = get_video_info(self.state.video_path)
            
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("ê¸¸ì´", format_time(info['duration']))
            with col2:
                st.metric("FPS", f"{info['fps']:.1f}")
            with col3:
                st.metric("í•´ìƒë„", f"{info['width']}x{info['height']}")
            with col4:
                st.metric("í¬ê¸°", f"{info['size_mb']:.1f} MB")
    
    def _show_user_guide(self):
        """ì‚¬ìš© ê°€ì´ë“œ í‘œì‹œ"""
        st.info("""
        ### ğŸ¯ CutStudio Enhanced ì‚¬ìš©ë²•
        
        1. **íŒŒì¼ ì—…ë¡œë“œ**: ê°•ì˜ ì˜ìƒ ë˜ëŠ” ì˜¤ë””ì˜¤ íŒŒì¼ ì—…ë¡œë“œ
        2. **í™”ì ë¶„ì„**: AIê°€ êµìˆ˜/í•™ìƒ ìŒì„± ìë™ êµ¬ë¶„
        3. **ìŠ¤ë§ˆíŠ¸ í¸ì§‘**: ì›í´ë¦­ìœ¼ë¡œ í•„ìš”í•œ ë¶€ë¶„ë§Œ ì¶”ì¶œ
        4. **êµìœ¡ ìš”ì•½**: ê°•ì˜ ë‚´ìš©ì„ êµ¬ì¡°í™”ëœ ë¬¸ì„œë¡œ ë³€í™˜
        
        **ğŸ’¡ Pro Tip**: í™”ì ë¼ë²¨ì„ ì§€ì •í•˜ë©´ ë” ì •í™•í•œ ì¶”ì¶œì´ ê°€ëŠ¥í•©ë‹ˆë‹¤!
        """)
    
    # ì¶”ê°€ í—¬í¼ ë©”ì„œë“œë“¤...


# ì•± ì‹¤í–‰
if __name__ == "__main__":
    app = EnhancedCutStudioApp()
    app.run()